id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
id,job_title,company_name,time_posted,num_applicants,description,seniority_level,employment_type,job_function,industries,created_on
1,Data Engineer,McDonald's,4 days ago,Over 200 applicants,"McDonald's evolving Accelerating the Arches growth strategy puts our customers and people first and demonstrates our competitive advantages to strengthen our brand. We are recognized on lists like Fortune’s Most Admired Companies and Fast Company’s Most Innovative Companies.Doubling Down on the 4Ds (Delivery, Digital, Drive Thru, and Development)Our growth pillars emphasize the critical role technology plays as the best-in-class, global omni-channel restaurant brand. Technology enables the organization through digital technologies, and improving the customer, crew and employee experience each and every day!Global Technology forging the wayLeading the digitization of our business is the Technology organization made up of innovation specialists who build industry defining tech using the latest innovations and platforms, like AI and edge computing to deliver on the next set of groundbreaking opportunities for the business. We take on technology innovation challenges at an incredible scale, and work across global teams who are always hungry for a challenge! This provides access to compelling career paths for technologists. It’s bonus points when you get to see your family and friends use the tech you build at their favorite McD restaurant.Job DescriptionMcDonald’s Global Technology – Customer 360 team is looking to hire a Data Engineer/Site Reliability Engineer (SRE) with a deep understanding of data product lifecycle, standards, and practices. This position is where you’ll play a key role in designing, implementing, and maintaining robust infrastructure. Collaborate with development teams, automate processes, and ensure system reliability through proactive monitoring and incident response. Bring your expertise in scripting, cloud technologies, and containerization to optimize performance and contribute to our commitment to technological excellence.Responsibilities:Design, implement, and maintain scalable and reliable infrastructure.Collaborate with development teams to enhance system architecture for optimal performance and stability.Implement automation tools for continuous monitoring, testing, and deployment.Respond to and resolve incidents, ensuring minimal downtime and quick recovery.Conduct root cause analysis of reliability issues and implement preventive measures.Optimize system performance and troubleshoot complex issues across the tech stack.Collaborate on capacity planning and scalability initiatives.Ensuring data security and compliance with data governance policies and regulations.Stay updated on industry best practices and emerging technologies in site reliability.Develops a solid understanding of the technical details of data domains and clearly understands what business problems are being solved.Designing and developing data pipelines and ETL processes to extract, transform, and load data from various sources into AWS data storage solutions (e.g., S3, Redshift, Glue).Implementing and maintaining scalable data architectures that support efficient data storage, retrieval, and processing.Building and optimizing data integration workflows to connect data from different systems and platforms.Managing data infrastructure on AWS, including capacity planning, cost optimization, and resource allocation.Ability and flexibility to coordinate and work with teams distributed across time zones. For instance, early morning/late evening hours to coordinate with teams in India.QualificationsBachelor’s degree in computer science, related field, or equivalent experience.Proven experience in a Site Reliability Engineer or similar role.5+ years of strong experience in data engineering, specifically with AWS backend tech stack, including but not limited to S3, Redshift, Glue, Lambda, EMR, and Athena.5+ years of hands-on experience with data modeling, ETL development, and data integration techniques.5+years of proficiency in programming languages commonly used in data engineering, such as PythonWorking knowledge of relational and dimensional data design and modeling in a large multi-platform data environmentSolid understanding of SQL and database concepts.Expert knowledge of quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Expert Knowledge of data, master data, and metadata-related standards, processes, and technology.Ability to drive continuous data management quality (i.e., timeliness, completeness, accuracy) through defined and governed principles.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of tools.Demonstrated experience in data management and data governance capabilities.Familiarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data-related questions.Excellent communication and collaboration skills to work effectively in cross-functional teams.Experience with E2E solutions using Kafka Real-time data processing.Experience with Kafka implementation and optimizationsPreferred Requirements:Experience with GCPExperience with JIRA and Confluence as part of project workflow and documentation tools is a plus.Experience with Agile project management methods and terminology a plusFamiliarity with CI/CD pipelines.Experience with infrastructure as codeExperience performing Database MigrationsAdditional InformationMcDonald’s is an equal opportunity employer committed to the diversity of our workforce. We promote an inclusive work environment that creates feel-good moments for everyone. McDonald’s provides reasonable accommodations to qualified individuals with disabilities as part of the application or hiring process or to perform the essential functions of their job. If you need assistance accessing or reading this job posting or otherwise feel you need an accommodation during the application or hiring process, please contact mcdhrbenefits@us.mcd.com. Reasonable accommodations will be determined on a case-by-case basis.McDonald’s provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to sex, sex stereotyping, pregnancy (including pregnancy, childbirth, and medical conditions related to pregnancy, childbirth, or breastfeeding), race, color, religion, ancestry or national origin, age, disability status, medical condition, marital status, sexual orientation, gender, gender identity, gender expression, transgender status, protected military or veteran status, citizenship status, genetic information, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Nothing in this job posting or description should be construed as an offer or guarantee of employment.",Associate,Full-time,Information Technology,Restaurants,2024-05-12
2,Data Engineer,Calm,2 weeks ago,Over 200 applicants,"About CalmCalm is on a mission to support everyone on every step of their mental health journey. With the #1 app for sleep, meditation and relaxation as well as a growing library of digital, evidence-based mental health programs, Calm offers trusted support for individuals and organizations alike. Our flagship consumer app provides personalized content and activities – featuring a range of experts and beloved celebrity voices – to help users manage stress, improve sleep and live mindfully. Our workplace and healthcare solutions offer a consumer-friendly approach to clinical content and HIPAA-compliant resources in order to drive positive health and business outcomes. Named a TIME100 Most Influential Company, Calm supports more than 150 million people and 3,500 organizations across seven languages and 190 countries.What We DoAs a data organization, we focus on making data a competitive advantage for Calm. We’re product-minded, team-oriented, and grounded in our mission of making the world a happier and healthier place. We work closely with teams across the company such as product, finance, marketing, data science, and more. As a team, we strive to always improve.What You’ll DoWe’re looking for someone who is comfortable with ambiguity, assesses what needs to be done, and delivers with the right balance of velocity and technical debt. As a Data Engineer, you’ll leverage all sorts of data, from application event streams to product databases to third-party data, to help stakeholders create products and answer business questions. Our stack spans AWS and GCP, with technologies like Airflow, Redshift, BigQuery, Postgres, Spark, and dbt. Specifically, you will:Work with business stakeholders to understand their goals, challenges, and decisionsAssist with building solutions that standardize our data approach to common problems across the companyIncorporate observability and testing best practices into projectsAssist in the development of processes to ensure our data is trusted and well-documentedEffectively work with data analysts on refining the data model used for reporting and analytical purposesImprove availability and consistency of data points crucial for analysisSome past projects include:Standing up a reporting system in BigQuery from scratch, including data replication, infrastructure setup, dbt model creation, and integration with reporting endpointsCreating a user-level feature store and related API endpoints to support machine learning tasks such as content recommendation and persona creationRemodeling a critical data pipeline to decrease our model count by 50% and reduce run time by 83%Setting up scalable APIs to integrate our Data Warehouse with 3rd party applications for personalization that reaches tens of millions of customersRevamping orchestration and execution to reduce critical data delivery times by 70%Who You AreProficiency with SQL and an object-oriented languageExperience with RDBMS, data warehouses, and event systemsExperience in building data pipelines that scaleAbility to translate non-technical business requirements into technical solutions, and translate technical solutions to business outcomesStrong communication skillsPragmatism: balancing scrappiness and rigorNice to HavesPython programing experienceExperience with data lakesExperience building across cloudsSome experience in Infrastructure as Code tools like TerraformKnowledge of different data modeling paradigms, e.g. relational, data vault, and medallionMinimum RequirementsThis role typically requires 5+ years of related experienceThe anticipated salary range for this position is $159,300- $223,000. The base salary range represents the low and high end of Calm’s salary range for this position. Not all candidates will be eligible for the upper end of the salary range. Exact salary will ultimately depend on multiple factors, which may include the successful candidate's geographic location, skills, experience and other qualifications. This role is also eligible for equity + comprehensive benefits + 401k + flexible time off.Please note that Calm may leverage artificial intelligence technology in the application review process.Calm is committed to providing reasonable accommodations for qualified individuals with disabilities, including disabled veterans. Please contact Calm’s Recruiting team if you need a reasonable accommodation, assistance completing any forms, or to otherwise participate in the application process. You can reach the Recruiting team at recruitingaccommodations@calm.comWe believe that mental health is health, and every person should be considered in the discussion. That’s why we’re proud to be an equal opportunity workplace, committed to providing equal employment opportunities to all applicants and employees regardless of race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, medical condition, genetic information, military or veteran status, gender identity or expression, sexual orientation, or any other characteristic protected by applicable federal, state or local law.Calm is deeply committed to diversity, equity and inclusion. We strive to create a mindful and respectful environment where everyone can bring their authentic self to work, and experience a culture that is free of harassment, racism, and discrimination.Calm participates in e-verify. E-verify provides the federal government with your Form I-9 information to confirm that you are authorized to work in the U.S.Right to WorkE-Verify Participation",Entry level,Full-time,Information Technology,Wellness and Fitness Services,2024-05-12
3,Junior Data Engineer,NielsenIQ,2 days ago,Over 200 applicants,"Company DescriptionREFID442121At NIQ, we deliver the most complete and clear understanding of consumer buying behavior that reveals new pathways to growth. We are looking to hire a Junior Data Engineer our large North American retail client.Job DescriptionAs a Junior Data Engineer, you will help create custom, robust, data-driven solutions that drive faster and more effective business decisions at a large North American retail client. We are seeking support primarily in back-end data warehousing and ETL processes, and secondarily in the creation of front-end dashboards and data visualizations.This is your opportunity to work with world-class data assets and deliver value at a massive scale. Working as part of a development team and in collaboration with your client-facing counterparts, the Junior Data Engineer will contribute to overall client satisfaction and team success against annual objectives. A strong candidate will reliably manage data warehouse and ETL content/processes, proactively identify automation opportunities, and help execute them.Build and maintain data pipelines to ingest data from multiple internal and external data sources to a data warehouseConstruct SQL queries to aggregate and model data for analysis. Create and implement automated processes that ensure quality and eliminate unnecessarily manual processes. Create and maintain documentation on all projects and procedures. Proactively identify issues and work to resolve in a timely manner. Work cross-functionally with internal and external teams responsible for database systems and client deliverables. About YouYou know how to identify opportunities for efficiency. You can continuously leverage online project management and documentation tools. You are a self-starter with the ability to manage complex projects and conflicting priorities. You deliver on what you promise. You are a logical problem solver who pays close attention to detail. You have demonstrated strength in analytics through project work and/or internship experience. You have a desire to grow at one of the world’s largest data companies and a desire to help others.Qualifications1+ years of experience with a Bachelor’s Degree in relevant Computer Science, Information Management or Engineering disciplineBasic to Intermediate level of experience in SQL. Proficient in Microsoft Excel. Ability to function in a team environment. Demonstrated ability to quickly learn, adopt and apply new technologies Highly self-motivated, enthusiastic and committed to delivering first class services. Experience with Power BI a plus. Experience with Snowflake, Google Cloud, AWS, or other cloud-based services a plus. Additional InformationOur BenefitsFlexible working environmentComprehensive health insuranceLife assurancePension planVolunteer time offLinkedIn LearningEmployee-Assistance-Program (EAP)About NIQNIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™. NIQ is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population.For more information, visit NIQ.comWant to keep up with our latest updates?Follow us on: LinkedIn | Instagram | Twitter | FacebookOur commitment to Diversity, Equity, and InclusionNIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide. Learn more about how we are driving diversity and inclusion in everything we do by visiting the NIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion",Mid-Senior level,Full-time,Administrative,Market Research,2024-05-12
4,Data Engineer,rag & bone,2 weeks ago,Over 200 applicants,"We are seeking a highly skilled and motivated Data Engineer to join our team. The ideal candidate will have strong proficiency in Python programming language, extensive experience with Oracle PL/SQL, and a solid understanding of Azure Serverless compute resources. As a Data Engineer, you will be responsible for designing, implementing, and maintaining scalable data pipelines and solutions to support our data-driven initiatives.ResponsibilitiesData Pipeline Development: Design, develop, and maintain robust data pipelines to extract, transform, and load (ETL) data from various sources into our data warehouse using Python and Azure Serverless compute resources.Data Modeling and Optimization: Work closely with analysts to design and optimize data models for performance and scalability. Utilize Oracle PL/SQL for efficient data querying and manipulation.Database Management: Manage and administer Oracle databases, including schema design, indexing, and performance tuning to ensure data integrity and reliability.Cloud Infrastructure Management: Deploy, configure, and manage Azure Serverless compute resources, such as Azure Functions, Azure Logic Apps and Azure Data Factory, to support data processing tasks and workflows.Monitoring and Maintenance: Implement monitoring solutions to proactively identify and address issues with data pipelines and database performance. Perform regular maintenance tasks to ensure optimal performance and reliability of data infrastructure.Documentation and Collaboration: Document data pipelines, database schemas, and infrastructure configurations. Collaborate with cross-functional teams including data scientists, analysts, and software engineers to understand data requirements and deliver effective solutions following our SCRUM framework.Continuous Improvement: Stay up to date with emerging technologies and best practices in data engineering. Continuously evaluate and recommend improvements to enhance the efficiency, scalability, and reliability of our data infrastructure.Qualifications: Bachelor's or master's degree in computer science, Engineering, or a related field. Proven experience as a Data Engineer or similar role, with a focus on building data pipelines and managing large-scale data infrastructure. Strong proficiency in Python programming language, with experience in developing data processing applications and scripts. Extensive experience with Oracle PL/SQL, including database design, optimization, and administration. Hands-on experience with Azure cloud services, particularly Azure Serverless compute resources (e.g., Azure Functions, Azure Logic Apps, Azure Data Factory). Solid understanding of data modeling principles and best practices. Excellent problem-solving skills and attention to detail. Strong communication and collaboration skills, with the ability to work effectively in a team environment. Experience with Oracle cloud infrastructure. Knowledge of big data technologies such as Hadoop, Spark, or Kafka. Experience with containerization technologies such as Docker and Kubernetes. Familiarity with Business Intelligence tools like MicroStrategy. Familiarity with data visualization tools such as Power BI or Tableau.Rules we live by | Rules you live byBe a Good Human - Be original, be authentic. Stand for diversity, equitability & inclusivity.Have No Fear - Innovate, solve problems Own Every Decision - Work together, get resultsQuality Matters – Not only with product but we see it in our peopleMake Shit Happen - Be disciplined, be competitiveBenefits Paid Time OffClothing AllowanceGenerous Employee DiscountPaid Parental LeaveMembership to Calm and access to other wellness benefitsMedical, dental, vision and ancillary benefits401kThe target salary for this position is $130,000-150,000 based on experience and expertise level in certain requirementsrag & bone is an EEO/Affirmative Action Employer. No employee or applicant is discriminated against because of race, color, sex (including pregnancy), age, national origin, religion, sexual orientation, gender identity, gender expression, parental status, status as a veteran, and basis of disability or any other federal, state or local protected class.Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. The employee is regularly required to sit; use hands to finger, handle, or feel and talk or hear. The employee is occasionally required to stand; walk; reach with hands and arms; climb or balance; stoop, kneel, crouch, or crawl; and taste or smell. The employee must occasionally lift and/or move up to 30 pounds. Specific vision abilities required by this job include close vision. The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
5,Data Engineer,Dr. Martens plc,2 weeks ago,Over 200 applicants,"SO, WHAT'S THE STORY?The D&A Team has set the vision “To make every DM decision better with data” and is embarking on a transformational journey to “Execute faster in creating trust, access and value globally from all our data to empower our colleagues to stride forwards”. It is an exciting time to join the D&A team, with the opportunity to both set and guide the team and DM’s strategic direction.As our Data Engineer you will be at the forefront of the team working on our data pipelines and data warehouse. You will be central to the success of the global Data Transformation initiative. We are at the beginning of the journey, so you will get the opportunity to define our data engineering approach, making fundamental changes through the design and implementation of a modern data ecosystem that underpins DMs bold growth ambitions. You will work closely with the broader business, supporting, challenging, and championing data and analytics for better decision making.THE GIGWorking independently, this will require the need for you to be able to not only work on tasks assigned to you with minimal help from your peers but also to be proactive on issues found during your working day.You will be responsible for representing the team in all data project meetings.Establishing the data warehouse as a trusted, stable, and reliable source of insight for the business.Building and maintaining robust and efficient data pipelines to bring internal and external data sources into our cloud-based platform for processing and ingesting into the DW.Building analytics datasets that utilize our pipelines to provide actionable insights into customer understanding, operational efficiency, and other key business performance metrics.You will possess strong organizational skills and attention to detail, including the ability to manage multiple tasks autonomously.You strive for improvement in your work and that of others, proactively identifying issues and opportunities.Provide hands-on support to users reporting data incidents, helping the wider team triage and respond to user queries promptly.Embedding technical architecture and documentation standards, governance, policies, processes, and procedures.THE STUFF THAT SETS YOU APARTExperience in/knowledge of:Azure and its various servicesAdvanced SQL skillsTransformations using DBTAzure Data Factory and Logic Apps development and orchestrationCloud data warehouse platforms such as Azure Data Warehouse, Synapse or SnowflakeDeveloping Spark/Databricks pipelines using PythonEvent-driven architecture and data streamingImplementing data lake standards and best practiceData warehouse design and modelling skills such as dimensional or Data Vault 2.0.Agile delivery methodologies, Azure DevOps and CI/CD pipelines.Experience use Jira and ConfluenceKnowledge of TerraformSupporting a BI Development team in maintaining data warehouse and pipeline development best practicesWe live and breathe Rebellious Self Expression at Dr. Martens, and there are 3 core values at the heart of it. They never stand alone, but work together as a balancing act of rights and responsibilities to support how we work together at DMs. BE YOURSELF. ACT COURAGEOUSLY. SHOW YOU CARE.To be our Data Engineer your technical capability will go hand in hand with:Great relationship management that delivers results through effective teamworkYou’ll be a proud custodian to our DM’s culture, embodying what we stand for and encouraging others to do the same.You will bring the outside-in; you’ll share best practice across the team / business and encourage idea sharing as well as collaborative problem solvingYou’ll lead the way and role model on all things DE&I & wellbeingAt Dr. Martens, we are committed to creating an environment in which we can all be our best and bring our authentic selves to work. We encourage applications, regardless of race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, age, veteran status, or disability. Diverse and inclusive teams have a positive impact on our brand; helping us to speak authentically to our consumers. We strive to develop a business where our people can thrive and feel empowered to express themselves. Because we believe everyone should feel supported and included, whatever their role in the Dr. Martens community.",Mid-Senior level,Full-time,Analyst and Information Technology,Retail Apparel and Fashion,2024-05-12
6,Data Engineer,Lyft,2 weeks ago,Over 200 applicants,"Lyft thrives on community—it's the essence of who we are and what we do. Our commitment to fostering an open, inclusive, and diverse environment is paramount, ensuring every team member is valued for their unique contributions.At Lyft, data isn't just part of our decision-making process; it's the foundation. It drives our ability to deliver exceptional transportation experiences and offers insights into the impact of our product launches and features.Joining Lyft as a Data Engineer means becoming a pivotal part of a team dedicated to shaping the future of transportation. You'll be tasked with developing robust data infrastructure—encompassing data transport, collection, and storage—and providing services that enable our leadership to make informed, risk-reducing decisions. We're in search of a Data Engineer to construct a scalable insurance data pipeline that will inform our financial strategies. Collaborating closely with our claims engineering, actuarial, and science teams, as well as our insurance partners, you'll lead the charge from technical proposal to final implementation. This role involves clear communication of technical challenges to both our internal teams and external partners, ensuring a cohesive approach to problem-solving.As the steward of our core data pipeline, which underpins Lyft's key metrics, you'll leverage your data expertise to refine data models and spearhead the creation and launch of scalable data pipelines. These efforts will support Lyft's expanding needs in insurance data processing and analytics, providing critical business and user behavior insights. With access to vast amounts of Lyft data, your work will empower teams across Analytics, Data Science, Engineering, and beyond, driving innovation and growth.Responsibilities:Design and implement insurance and claim-related data pipeline to help optimize insurance operation strategiesTune ETL and MapReduce job to improve data processing performancePartner with external insurance partners and Lyft business stakeholders to ensure seamless execution within established timelinesOwner of the core company data pipeline, responsible for converting the business and engineering need to efficient & reliable data pipelinesMain contributor to the team roadmap and lead the team to make the right technical decisionsExperience:3+ years of relevant professional experienceStrong experience with SparkExperience with Hadoop (or similar) Ecosystem, S3, DynamoDB, MapReduce, Yarn, HDFS, Hive, Spark, Presto, Pig, HBase, ParquetStrong skills in a scripting language (Python, Ruby, Bash)Good understanding of SQL Engine and able to conduct advanced performance tuningProficient in at least one of the SQL languages (MySQL, PostgreSQL, SqlServer, Oracle)Experience with workflow management tools (Airflow, Oozie, Azkaban, UC4)Comfortable working directly with data and business partners to bridge Lyft’s business goals with data engineeringPreferred to have experience of building and maintaining insurance related data pipeline for large organizations Benefits:Great medical, dental, and vision insurance optionsMental health benefitsFamily building benefitsIn addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off401(k) plan to help save for your future18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligiblePre-tax commuter benefitsLyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership ProgramLyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year. #HybridThe expected range of pay for this position in San Francisco is $144,000 - $180,000. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.",Mid-Senior level,Full-time,Information Technology,Ground Passenger Transportation,2024-05-12
7,Data Engineer,Ford Motor Company,1 week ago,Over 200 applicants,"Job DescriptionData Factory (DF) is a GDIA (Global Data Insights and Analytics) team supporting Ford+ and Ford’s data superiority vision. This role is within the GDIA Identity Resolution Team (IR). The IR team plays a pivotal role within our organization, focusing on analyzing and understanding complex data patterns to innovate and enhance customer profiles. Our mission is to empower businesses to unlock the full potential of their data, ensuring accurate, secure, and efficient identification across various platforms and systems. We are seeking a highly skilled AI/ML Data Engineer with expertise in Google Cloud Platform (GCP) to join our team. This individual will play a crucial role in developing and implementing automated, auditable best practices and processes to support both our business and technical communities. By harnessing the power of AI/ML on GCP, you will enhance our capabilities to deliver precise and scalable identity solutions.ResponsibilitiesDesign and develop robust, scalable data processing and machine learning pipelines on GCP to support identity resolution projects.Implement and optimize algorithms for AI-based identity matching, entity resolution, and data deduplication.Collaborate with data scientists and other stakeholders to translate complex requirements into effective, efficient data solutions.Leverage GCP services (e.g., BigQuery, Dataflow, AI Platform, Pub/Sub,Vertex AI,LLM, Looker Studio) to process, store, and analyze large datasets.Ensure data quality and integrity throughout the data lifecycle, applying best practices for data governance and compliance.Design and implement machine learning models to solve specific business challenges. Optimize data processing and feature engineering to enhance model performance.Monitor and evaluate the performance of ML models, making adjustments and improvements as needed.Stay abreast of new technologies and methodologies in AI/ML and data engineering to continuously improve our identity resolution capabilities.Work with Architecture, Data Factory, Data Ingestion, Cataloging, Quality, Metadata and Operations teams to implement strategic solutions.QualificationsBasic Qualifications:Requires a bachelor’s or foreign equivalent degree in computer science, information technology or a technology related fieldAbility to work effectively across organizations, product teams and business partners.Knowledge Agile (Scrum) Methodology, experience in writing user stories Database and SQL experience: Strong understating of Database concepts and experience with multiple database technologies – optimizing query and data processing performance.Experience with BigQuery SQL, AWS and/or Azure.Experience programming engineering transformation in Python or a similar language. Knowledge of Data Warehouse concepts – experience with Data Warehouse/ ETL processes Strong process discipline and thorough understating of IT processes (ISP, Data Security).Preferred Qualifications:Proven experience as a Data Engineer or Machine Learning Engineer, with a strong focus on identity resolution solutions.Proficiency in programming languages such as Python, and familiarity with SQL or NoSQL databases.Experience in building and optimizing data pipelines, architectures, and data sets.Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.Excellent problem-solving abilities and a passion for innovation.Hands-on Experience using Google Cloud Platform, AWS and/or Azure.Hands on experience in Python using libraries like NumPy, Pandas, nltk, xgboost etc.Understanding of Cluster computing frameworks like Spark Deep understanding of machine learning algorithms and principles.Experience with machine learning frameworks (TensorFlow, PyTorch).You may not check every box, or your experience may look a little different from what we've outlined, but if you think you can bring value to Ford Motor Company, we encourage you to apply!As an established global company, we offer the benefit of choice. You can choose what your Ford future will look like: will your story span the globe, or keep you close to home? Will your career be a deep dive into what you love, or a series of new teams and new skills? Will you be a leader, a changemaker, a technical expert, a culture builder…or all of the above? No matter what you choose, we offer a work life that works for you, including: Immediate medical, dental, and prescription drug coverage Flexible family care, parental leave, new parent ramp-up programs, subsidized back-up child care and more Vehicle discount program for employees and family members, and management leases Tuition assistance Established and active employee resource groups Paid time off for individual and team community service A generous schedule of paid holidays, including the week between Christmas and New Year’s Day Paid time off and the option to purchase additional vacation time.For a detailed look at our benefits, click here:  Benefit SummaryThis position is a salary grade 8.This position is a range of salary grades 8.Visa sponsorship is available for this position.Candidates for positions with Ford Motor Company must be legally authorized to work in the United States. Verification of employment eligibility will be required at the time of hire.We are an Equal Opportunity Employer committed to a culturally diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, color, age, sex, national origin, sexual orientation, gender identity, disability status or protected veteran status. In the United States, If you need a reasonable accommodation for the online application process due to a disability, please call 1-888-336-0660.SOUTHEAST MI RESIDENTS: Please note, this job is posted as remote unless the selected candidate lives within 50 miles of Dearborn, MI. We request the candidate to be onsite 1-2 days a week.#LI-Remote",Not Applicable,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
8,Data Engineer,"eTek IT Services, Inc.",2 weeks ago,Over 200 applicants,"Role : Data EngineerLocation : Cincinnati ,OHW2 ContractJd﻿Required SkillsWord, Databricks, PySpark, Python, SQL, AzureAdditional SkillsJob DescriptionIn serving data back, make accessible to analysts and PowerBI reporting. Can build dashboards on top of this area.Real time and batch data – large volume will be batch. Doesn’t change as often.Requirement to consume Kafka topic that will be real time in case a new consumer comes along and needs a seed file. One or two real time consumers.Senior needs to build out data pipelines from scratch. Stand up data domains in each line of business or specialized area. There is a lot coming down architecture center of excellence in terms of structure guidelines of what you should do. This resource will find common pattern or standard being used and adopt that. Someone calling out an area of improvement. Scratch would be ideal.Senior resource will be capable of outlining the patterns and creating the Jira and tickets that next line of engineers will be responsible for. Architects and senior leadership will create the process and hand off smaller tasks. Engineers need to be familiar with it but not necessarily the experts.ML won’t be tackled in this space right away. Plenty of timeSkills: jira,azure,architects,kafka,pyspark,data,sql,python,word,microsoft azure,databricks",Mid-Senior level,Contract,Information Technology,Information Technology & Services,2024-05-12
9,Data Engineer Intern,Cadent,2 weeks ago,Over 200 applicants,"Cadent powers the evolution of TV brand advertising. We provide marketers, agencies, operators, and media owners with data-driven solutions for buying and selling TV advertising. By connecting brands with opportunities across national inventory sources—cable, broadcast, and digital media—our technology improves efficiencies and boosts the results of linear, addressable, and cross-screen campaigns. As we continue to grow, we’re looking for a Data Engineer Intern to join our Data Engineering team for Summer 2024. The Intern will have an opportunity to gain hands-on experience by working directly with our teams. The Intern will also spend the spring on an individual project customized to their specific skill set which they’ll present to our Tech Leadership team at the end of the program. Details of the projects and timeline will be laid out by supervisors at the beginning of the program. The Intern will be responsible for fulfilling tasks set out by supervisors from the specific department they’re working in, including but not limited to:Use Python, SQL, Shell scripting, and Cloud technologies and other department-specific software to complete day-to-day assignments. *Python experience is required*Collaborate effectively with other members of the data engineering team and broader data services group including but not limited to Data Engineers, Data Scientists, Analytics Engineers, Performance Engineers, Software Engineers and Business Intelligence AnalystsConduct research and present findings to the Data Engineering team and business stakeholdersCollaborate with the team in Agile Sprint Planning, demos, seminars, and other team meetings. Perks:Competitive payCollege credit (if applicable) Requirements:A senior pursuing a Master’s degree at a college or university majoring in a field closely related to the department they are interning preferably computer science or related fieldAble to commit to a full-time (35-40 hours per week) work schedule between June 11, 2024 - August 16, 2024.Proficient in Python, SQL, and Shell scripting and Cloud data processing technologiesBackground in Computer Science and software engineeringExcellent verbal and written communicatorsSelf-motivated with a desire to learn from a rapidly growing companyConfident to take initiative and collaborate with teammatesSo, if the leading edge of media technology is the place you want to be, please contact us today and let’s start the conversation! Cadent is an Equal Opportunity Employer and is committed to supporting all it’s employees when it comes to Inclusion & Diversity. Cadent’s policy is to provide equal opportunity for applicants & employees without regard to race, color, religion, creed, gender, gender identity or expression, sexual identity or orientation, age, national origin or ancestry, citizenship, disability or medical condition (including pregnancy, childbirth, or related medical condition), sexual and reproductive health decisions, genetic information, marital status (including domestic partnerships and civil unions), pregnancy, culture ancestry, familial or caregiver status, military status, veteran status, socioeconomic status, unemployment status, status as a victim of domestic violence or any other basis prohibited by law. and will not discriminate against the basis of disability. This commitment is honored when it comes to decisions on hiring, recruiting, training, promotions, compensations, benefits, transfers and terminations. Cadent is seeking to actively engage with our employees from a wide variety of cultures and to connect with our clients differently. Our workforce has generational diversity that supports greater innovation when we maximize representation of all diversity. Our active employee resource groups promote engagement across all groups of individuals that are represented within the company and externally",Internship,Internship,Information Technology,Advertising Services,2024-05-12
10,Data Engineer,Unilever,4 days ago,Over 200 applicants,"Background & Purpose Of The JobThe data engineer is responsible for the analysis of multiple data sets, coding and scripting of planograms, delivery of reporting to the advising team, and partnering with the Target Merchant teams to bring the most accurate, strategy driven assortments to the store. Through the integration of both customer and consumer data you will build and land planogram automation in accordance with the merchant strategy. This role exists to make sense of vast amounts of data in a way that enable Unilever’s Category team to act and enhance the way they engage with our Retailer Customers. The ideal candidate will be analytical, detail-oriented, and able to articulate the value of planograms through automation.Who You AreYou’re a born leader: You will become the ‘go-to’ Category Strategy resource for the team by providing insight-led, actionable recommendations.You’re a storyteller: You will have access to one of the industry’s most-robust data sources to turn insights into action by providing differentiated thought leadership delivered through simplified stories, to gain acceptance and adoption of category strategies.You’re a strategy specialist: You’ll integrate multiple sources of insight to define where to play and how to win over the short and long term. You’re able to develop plans for execution and engagement with appropriate customer contact points, timing, & content based on industry research and Unilever knowledge.You’re a visionary: Figuring out problems with limited direction doesn’t faze you. You have the intuition to anticipate issues and opportunities by elevating analyses beyond reporting to develop and translate insight into retail action.You’re a dot connector: You will penetrate multiple cross-functional teams and the customer to define priorities, objectives, and successfully influence action plans, specific to Target’s business plans.You’re an innovator: You have a healthy dissatisfaction for the status quo and through access to rich capabilities and tools, you will set a constant eye on the future to garner insights and develop solutions that drive incremental growth for Target and Unilever.What You’ll DoManipulate and analyze large volumes of data, combining both retailer and consumer data.Write and maintain automation scripts and applications to deliver highly accurate, complete planograms on time each transition cycle.Deliver actionable insights to help decision making via visual reporting platforms in collaboration with the advising team.Management of the data flow and architecture for the category as it relates to the category level dataset.Developing the skills and talent to stay ahead of the competition providing value and consistency to the customer over time.What You’ll Need To SucceedExperience with BlueYonder (JDA) and the programming process (POGs, reporting, analytics)Strong technical skills in the likes of C#, SQL, Python, PBi/DAX or similar software and languagesData driven with a strong commercial acumenStrong communication skillsUnderstanding of retail & shopping landscape and experience working directly with customersAbility to analyze large and complex data sets with proven experience in delivering recommendations to senior stakeholders.What We Can Offer YouCulture for Growth | Top Notch Employee Health & Well Being Benefits | Every Voice Matters | Global Reach | Life at Unilever | Careers with Purpose | World Class Career Development Programs | Check Out Our Space | Focus On SustainabilityPay: The pay range for this position is $84,400 to $126,600. Unilever takes into consideration a wide range of factors that are utilized in making compensation decisions including, but not limited to, skill sets, experience and training, licensure and certifications, qualifications and education, and other business and organizational needs.Bonus: This position is bonus eligible. Long-Term Incentive (LTI): This position is LTI eligible.Benefits: Unilever employees are eligible to participate in our benefits plan. Should the employee choose to participate, they can choose from a range of benefits to include, but is not limited to, health insurance (including prescription drug, dental, and vision coverage), retirement savings benefits, life insurance and disability benefits, parental leave, sick leave, paid vacation and holidays, as well as access to numerous voluntary benefits. Any coverages for health insurance and retirement benefits will be in accordance with the terms and conditions of the applicable plans and associated governing plan documents.Unilever is an organization committed to diversity and inclusion to drive our business results and create a better future every day for our diverse employees, global consumers, partners, and communities. We believe a diverse workforce allows us to match our growth ambitions and drive inclusion across the business. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.Employment is subject to verification of pre-screening tests, which may include drug screening, background check, credit check and DMV check.If you are an individual with a disability in need of assistance at any time during our recruitment process, please contact us at NA.Accommodations@unilever.com. Please note: This email is reserved for individuals with disabilities in need of assistance and is not a means of inquiry about positions or application statuses.",Entry level,Full-time,Sales and Business Development,"Manufacturing, Food and Beverage Manufacturing, and Food and Beverage Services",2024-05-12
11,Data Engineer,Caterpillar Inc.,2 weeks ago,Over 200 applicants,"Job Title: Data Engineer 3Location: Chicago, IL (Hybrid 1-2 days in a week office)Duration: 12 MonthsPosition’s Contributions to Work Group: Python & AWS development to build, enhance and maintain monitoring capabilities.Reason/motivation for request: - BackfillTypical task breakdown: - Develop datasets and microservices in support of new monitoring solutions and automations to accelerate issue detection and correction. - Transformation of data to enable machine learning and/or monitoring of anomalies. - Consumption of metadata to enable anomaly alarms and monitoring. - Employee is also responsible for performing other job duties as assigned by Caterpillar management from time to time.Interaction with team: - Liaise with designers, engineers, and support teams to improve data pipeline performance & reliability.Work environment: - Work independently and collaborate with internal team and cross functional teams via Teams meetings, chat, and/or emailEducation & Experience Required: - Bachelor's degree in computer programming or a relevant field required and 5-7 years’ experience required. - 4+ years’ experience with Master’s degree or higher - Associates degree with a minimum of 10 years of experience in this field. Technical Skills (Required) · Experience with serverless design in AWS · Four years or more of experience in data engineering and/or software development. · Three years or more of experience with development, operations, or architecture in AWS using Python. · Experience with development and delivery of microservices using serverless AWS services (S3, RDS, Aurora, DynamoDB, Lambda, SNS, SQS, Kinesis, IAM) · Strong competency in testing, including unit testing to coverage standards and integration testing. · (Desired) · Software development experience with object-oriented development and design patterns · AWS technical certifications (Developer Associate, Solution Architect Associate) · Familiarity with machine learning and data design to support machine learning · Experience with productionizing machine learning workloads · Experience with ElasticSearch/ELK, Kibana, Grafana, and/or Prometheus · Experience with OpenTelemetry Soft Skills (Required) · Verbal and written communication skills, problem solving skills, customer service and interpersonal skills. · Basic ability to work independently and manage one’s time. (Desired) · Ability to work collaboratively in a complex, rapidly changing, and culturally diverse environment. · Ability to clearly communicate complex technical ideas. · Comfortable working in a dynamic environment where digital is still evolving as a core offering.Disqualifiers/Red Flags: · No experience with automated testing · Make sure to list on the resume where the candidate resides or they will be DQ · No public cloud experience.Interview Process: - 1st round: initial round ( Manager asking non-technical questions)- 30 min - 2nd round: Technical interview ( 30 min) - Interviews will be via teams",Mid-Senior level,Contract,Other,Manufacturing and Industrial Machinery Manufacturing,2024-05-12
12,Data Engineer,LTIMindtree,2 days ago,Over 200 applicants,"About Us:LTIMindtree is a global technology consulting and digital solutions company that enables enterprises across industries to reimagine business models, accelerate innovation, and maximize growth by harnessing digital technologies. As a digital transformation partner to more than 700+ clients, LTIMindtree brings extensive domain and technology expertise to help drive superior competitive differentiation, customer experiences, and business outcomes in a converging world. Powered by nearly 90,000 talented and entrepreneurial professionals across more than 30 countries, LTIMindtree — a Larsen & Toubro Group company — combines the industry-acclaimed strengths of erstwhile Larsen and Toubro Infotech and Mindtree in solving the most complex business challenges and delivering transformation at scale. For more information, please visit www.ltimindtree.com Job Title:  Data Engineer  Work LocationBellevue WA Job Description:Experience in SQL Programming language.Knowledge of end-to-end process on creation maintenance of Data pipelines.Working experience on Azure DevOps is a must.Working Knowledge on Azure Data factory Azure Data Lake and Azure Data Lake storage.Proficiency in Azure synapse.Implement end end data pipelines using cosmos Azure Data factory.Experience on Version control ADO GIT CI CD.Should have good analytical thinking and Problem solving.Ability to showcase data analysis effectively using KPI’s metrics charts.Experience with Data quality implementations assessing data correctness completeness uniqueness etc.Experience working on PII GDPR handling sensitive data encryption decryption.Able to work as Individual contributor and with offshore team.Responsibilities Expectations from the role:Good communication and coordination skills.Requirement Analysis and questioning skills.Create Maintain and Enhance Data Pipeline.Daily status reporting interacting with Leads.Data Platform Product telemetry Analytical thinking.Data Validation of the new streams.Data quality check of the new streams.Debugging of issues and making good quality code fixes.Monitoring of data pipeline created in Azure Data factory.Updating the Tech spec and wiki page for each implementation of pipeline.Updating ADO on daily basis.Good to have:Hands on in Visualization like PowerBI.Marketing Campaign experiences.Technical Skillset Required Azure Data Factory EDL SQL Server 2016 Azure SynapseAzure Cosmos DB Azure Databricks PySpark Python Excel Azure Databricks EDLTechnical Skillset Good to have Power BI Azure synapse.Benefits/perks listed below may vary depending on the nature of your employment with LTIMindtree (“LTIM”): Benefits and Perks:Comprehensive Medical Plan Covering Medical, Dental, VisionShort Term and Long-Term Disability Coverage401(k) Plan with Company matchLife InsuranceVacation Time, Sick Leave, Paid HolidaysPaid Paternity and Maternity Leave The range displayed on each job posting reflects the minimum and maximum salary target for the position across all US locations. Within the range, individual pay is determined by work location and job level and additional factors including job-related skills, experience, and relevant education or training. Depending on the position offered, other forms of compensation may be provided as part of overall compensation like an annual performance-based bonus, sales incentive pay and other forms of bonus or variable compensation. Disclaimer: The compensation and benefits information provided herein is accurate as of the date of this posting. LTIMindtree is an equal opportunity employer that is committed to diversity in the workplace. Our employment decisions are made without regard to race, color, creed, religion, sex (including pregnancy, childbirth or related medical conditions), gender identity or expression, national origin, ancestry, age, family-care status, veteran status, marital status, civil union status, domestic partnership status, military service, handicap or disability or history of handicap or disability, genetic information, atypical hereditary cellular or blood trait, union affiliation, affectional or sexual orientation or preference, or any other characteristic protected by applicable federal, state, or local law, except where such considerations are bona fide occupational qualifications permitted by law. Safe return to office:In order to comply with LTIMindtree’ s company COVID-19 vaccine mandate, candidates must be able to provide proof of full vaccination against COVID-19 before or by the date of hire. Alternatively, one may submit a request for reasonable accommodation from LTIMindtree’s COVID-19 vaccination mandate for approval, in accordance with applicable state and federal law, by the date of hire. Any request is subject to review through LTIMindtree’s applicable processes.",Mid-Senior level,Full-time,Information Technology and Engineering,IT Services and IT Consulting,2024-05-12
13,Data Engineer,Guzman Energy,2 weeks ago,Over 200 applicants,"Data Engineer:Position Overview:Guzman Energy is seeking an experienced data engineer with demonstrated experience designing and building scalable databases across a wide range of data sources. The Data Engineer will be responsible for structuring Guzman’s Google BigQuery database to efficiently pull data from multiple systems and produce dynamic visualizations and analytics. The Data Engineer will be part of the Technology team and report directly to the Technical Project Manager.The position is in Denver, Colorado. The company has a policy for in-office work Monday through Thursday, with remote work on Fridays.Compensation Range: annual base salary is $100-120k based on experience and skillsResponsibilities:Design data models for storage and retrieval to meet analytics requirementsSynthesize data from multiple data sources into a structure that allows for comparison across assets, loads, and other cuts of industry-specific dataBuild scalable, performant infrastructure for delivering clear business insights from a variety of data sourcesBuild performant and informative BI dashboards to allow business users to analyze complex data to improve trading and business practicesCollaborate with the Technical Project Manager and Software Engineer to deliver high quality productsQualifications and Requirements:Bachelor’s degree in computer engineering, data, computer science, or a related field of study or equivalent experienceMinimum of 3-5 years as a data engineer or similar roleExpert-level SQL skillsExperience working within a cloud-based environment such as Google BigQuery, AWS, Snowflake etc.Proficiency in PythonProficiency developing within a BI tool such as Tableau, PowerBI, Looker etc.Experience working within JIRA and AzureDevOps, and accessing data from SFTP servers or ODBC connections preferredFamiliarity with the electric utility industry a plusAbout Guzman Energy GroupGuzman Energy Group is a new type of energy company, one designed specifically to help transition the old energy economy into the renewable age. We are a full-service wholesale power provider focused on providing market-based solutions to address our customers’ energy challenges. We are a fast-paced group in growth mode, tackling multiple strategic initiatives with the goal to deliver reliable, affordable and sustainable power to our customers.Guzman Energy Group provides an environment where all employees are valued, respected and provided with the opportunity to achieve maximum performance. We offer a comprehensive pay package that includes competitive compensation, annual company and performance-based incentive bonuses, paid time off, medical benefits, 401(K) programs with employer match and nine holidays per year.Please email your resume to, Bettina Gensollen, at bgensollen@guzmanenergy.comGuzman is an equal opportunity employer and hires without regard to race, color, religion, ancestry, sex, citizenship, national origin, marital, military and veteran status, age, disability, medical condition, genetic information, gender identity, gender expression, sexual orientation, family status, pregnancy, or any other characteristic protected by federal, state, or local law.",Mid-Senior level,Full-time,"Information Technology, Engineering, and Science","Utilities, Electric Power Transmission, Control, and Distribution, and Electric Power Generation",2024-05-12
14,Data Engineer II,Cinemark,1 week ago,,"Join Our TeamAs part of our Cinemark Universe, you'll discover fun opportunities with real growth potential and plenty of perks. With 500+ theatres and nearly 6,000 screens; we're truly a global presence of 20,000 movie lovers working together to make unforgettable experiences.DescriptionRole Summary:Develop and maintain scalable data pipelines and build out new integrations to support continuing increases in data volume and complexity. Collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility, and fostering data-driven decision making across the organization. Implement processes and systems to monitor data quality, ensuring production data is accurate and available for key stakeholders and business processes that depend on it. Write unit/integration tests, contribute to engineering wiki, and document work. Automate manual processes and optimize data delivery. Implement data ingestion routines using best practices in data modeling, ETL/ELT processes by leveraging Microsoft Azure technologies. Assist business users with report development through SQL queries, Power BI, or other query tools. Produce comprehensive usable dataset documentation and metadata. Work with internal customers to solve, implement, and lead through the deployment of technical solutions for their business needs. Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues. Design data integrations and data quality framework. Understand and enforce data quality and governance standards like data lineage and traceability. Contribute to data strategy in support of data and data architecture scalability and ability to meet business needs.RequirementsMaster’s degree in Computer Science, Computer Engineering, Management of Information Systems, or a related field and 2 years of experience developing and maintaining scalable data pipelines; performing data modeling; and utilizing ETL/ELT processes, Microsoft Azure, SQL, Power BI, and Python.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
15,Data Engineer II,Spotify,3 days ago,Over 200 applicants,"We are looking for a Data/Backend Engineer to join our team. We are at the forefront of deriving foundational knowledge through vectors and representations of music content and users’ taste, which are key for Spotify teams to create personalized, engaging experiences. This is a unique opportunity to help develop and improve our next-gen user representations, and shape the way Spotify recommendations work. You’ll be able to grow your skills in engineering at scale, drive a ton of business impact, and join a high-energy, positive team environment!Join us and you’ll keep millions of users listening to great recommendations every day.What You'll DoBuild large-scale batch and real-time data pipelines with data processing frameworks like Scio, Google Cloud Platform and the Apache BeamDevelop, deploy, and operate Java services that impact millions of usersWork on machine learning projects powering the experience that suits each user individuallyCollaborate with other engineers, product managers and stakeholders, taking on learning and leadership opportunities that will arise every single dayDeliver scalable, testable, maintainable, and high-quality codeShare knowledge, promote standard methodologies, making your team the best version of itself through mentorship and constructive accountability.Who You AreYou have Data Engineering experience and you know how to work with high- volume, heterogeneous data, preferably with distributed systems such as Hadoop, BigTable, Cassandra, GCP, AWS or AzureYou know Scala language well, and are interested in spreading this knowledge in the teamYou have experience with one or more higher-level JVM-based data processing frameworks such as Beam, Dataflow, Crunch, Scalding, Storm, Spark, Flink etcYou have hands-on experience with high-volume services in Java. Python experience is also a plusYou might have worked with Docker as well as Luigi, Airflow, or similar toolsYou care about quality and you know what it means to ship high quality codeYou care about agile software processes, data-driven development, reliability, and responsible experimentationYou understand the value of collaboration and partnership within teamsIf you have experience with (of interest in) product management, that would be a plus, but it’s not requiredWhere You'll BeWe offer you the flexibility to work where you work best! For this role, you can be within the Eastern time zone as long as we have a work location. The United States base range for this position is $122,716.00- 175,308.00 plus equity. The benefits available for this position include health insurance, six month paid parental leave, 401(k) retirement plan, monthly meal allowance, 23 paid days off, 13 paid flexible holidays, paid sick leave. These ranges may be modified in the future.Today, we are the world’s most popular audio streaming subscription service.",Entry level,Full-time,Engineering,Musicians,2024-05-12
16,Data Engineer,STARK BANK,2 weeks ago,Over 200 applicants,"Company Intro:Our world is immersive and visceral. Content today is static and boring. We are Momenti, video that you interact with, bringing visceral experiences to all content. Build deeper connections and emotions with multi-dimensional video, and bring life to content by breaking the 4th wall. Join the content revolution! The world is alive, and so should your captured moments. Momenti is here.Momenti is a startup with technologies for creating and playing Gesture Interactive Video (GIV) that responds to user gestures. We are developing service software that enables content creation, editing, and playback based on our unique media model and providing these services to users worldwide. We are also developing data analysis technologies to analyze and visualize user gestures to improve the quality and service of media content (you can experience the technology demo on our website https://momenti.tv ).Job summary:Collect, analyze, and visualize gesture interaction data generated by users worldwide in real time and derive insights to improve the content usage experience based on this data. We are building a data pipeline, operating data storage, and improving query efficiency to convert data into value and deliver it with Momenti. We are looking for engineers who can participate with us.Job Responsibilities:Building and operating a data analysis pipelineBuilding and operating a data pipeline for monitoring systems for managing indicators (business, product)Working based on Cloud Pubsub for streamingAnalyzing user data and deriving business insightsFunnel Analysis, Heatmap Analysis, etc.MLOps, developing and operating machine learning modelsTech Stack Requirements:GCP, Cloud PubSub, BigQuery Cloud SQL (PostgreSQL), Cloud Storage, DBT, Metabase, GrafanaQualifications:Bachelor's degree in computer science, software engineering, information technology, or a related fieldExperience in building and operating a data pipeline on a cloud platformProgramming experience for automation (Python, Go, etc.)Experience using data analysis and data SaaS (Amplitude, Mixpanel, etc.)Preferred QualificationsExperience in data analysis based on machine learningExperience building advertising dashboards/back officesExperience in ML model serving/MLOps.Salary & Benefits: Full-time Position Salary range is $105,000 - 160,000 yr depending on experience Paid Time Off & Holiday Health, Dental, and Vision Insurance",Not Applicable,Full-time,Information Technology,Banking,2024-05-12
17,Data Engineer,Fusemachines,2 weeks ago,Over 200 applicants,"About FusemachinesFusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 350 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.About the role:This is a remote, W2 role responsible for designing, building, and maintaining the infrastructure required for data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics). Working in the Financial sector and implementing cyber-security use cases.Qualification / Skill Set Requirement:3+ years of real-world data engineering development experience in Snowflake and AWS (certifications preferred)Proven experience as a Snowflake Developer, with a strong understanding of Snowflake architecture and conceptsProficient in snowflake services such as snowpipe, stages, stored procedures, views, materialized views, tasks and streamsMust have previous experience working with security datasetsMust have experience working with TerraformStrong programming skills in SQL, with proficiency in writing efficient and optimized code for data integration, storage, processing, and manipulationRobust understanding of data partitioning and other optimization techniques in SnowflakeKnowledge of data security measures in Snowflake, including role-based access control (RBAC) and data encryptionHighly skilled in one or more languages such as Python, Scala, and proficient in writing efficient and optimized code for data integration, storage, processing and manipulationStrong knowledge of SDLC tools and technologies, including project management software (Jira or similar), source code management (GitHub or similar), CI/CD system (GitHub actions, AWS CodeBuild or similar) and binary repository manager (AWS CodeArtifact or similar)Skilled in Data Integration from different sources such as APIs, databases, flat files, event streamingGood understanding of Data Modeling and Database Design Principles. Being able to design and implement efficient database schemas that meet the requirements of the data architecture to support data solutionsStrong experience in working with ELT and ETL tools and being able to develop custom integration solutions as neededStrong experience with scalable and distributed Data Technologies such as Spark/PySpark, DBT and Kafka, to be able to handle large volumes of dataStrong experience in designing and implementing Data Warehousing solutions in AWS with RedShift. Demonstrated experience in designing and implementing efficient ELT/ETL processes that extract data from source systems, transform it (DBT), and load it into the data warehouseStrong experience in Orchestration using Apache AirflowExpert in Cloud Computing in AWS, including deep knowledge of a variety of AWS services like Lambda, Kinesis, S3, Lake Formation, EC2, ECS/ECR, IAM, CloudWatch, Redshift, etcGood understanding of Data Quality and Governance, including implementation of data quality checks and monitoring processes to ensure that data is accurate, complete, and consistentGood Problem-Solving skills: being able to troubleshoot data processing pipelines and identify performance bottlenecks and other issuesResponsibilities:Follow established design, constructed data architectures. Developing and maintaining data pipelines, ensuring data flows smoothly from source to destination. Handle ELT processes, including data extraction, loading, transformation and load data from various sources into SnowflakeEnsure the reliability, scalability, and efficiency of data systems are maintained at all timesAssist in the configuration and management of Snowflake data warehousing and data lake solutions, working under the guidance of senior team membersCollaborate closely with cross-functional teams including Product, Engineering, Data Scientists, and Analysts to thoroughly understand data requirements and provide data engineering supportContribute to data quality assurance efforts, such as implementing data validation checks and testsEvaluate and implement cutting-edge technologies and continue learning and expanding skills in data engineering and cloud platformsDevelop, design, and execute data governance strategies encompassing cataloging, lineage tracking, quality control, and data governance frameworks that align with current analytics demands and industry best practicesDocument data engineering processes and data flowsCare about architecture, observability, testing, and building reliable infrastructure and data pipelinesTakes ownership of storage layer, SQL database management tasks, including schema design, indexing, and performance tuningSwiftly address and resolve complex data engineering issues, incidents and resolve bottlenecks in SQL queries and database operationsAssess best practices and design schemas that matches business needs for delivering a modern analytics solution (descriptive, diagnostic, predictive, prescriptive)Be an active member of our Agile team, participating in all ceremonies and continuous improvement activitiesEqual Opportunity Employer: Race, Color, Religion, Sex, Sexual Orientation, Gender Identity, National Origin, Age, Genetic Information, Disability, Protected Veteran Status, or any other legally protected group status.Powered by JazzHRcBQJOWcwwb",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
18,Data Engineer,Meta,1 month ago,Over 200 applicants,"At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.Data Engineer Responsibilities:Partner with leadership, engineers, program managers and data scientists to understand data needsApply proven expertise and build high-performance scalable data warehousesDesign, build and launch efficient & reliable data pipelines to move and transform data (both large and small amounts)Securely source external data from numerous partnersIntelligently design data models for optimal storage and retrievalDeploy inclusive data quality checks to ensure high quality of dataOptimize existing pipelines and maintain of all domain-related data pipelinesOwnership of the end-to-end data engineering component of the solutionSupport on-call shift as needed to support the teamDesign and develop new systems in partnership with software engineers to enable quick and easy consumption of dataMinimum Qualifications:BS/MS in Computer Science or a related technical field5+ years of Python or other modern programming language development experience5+ years of SQL and relational databases experience5+ years experience in custom ETL design, implementation and maintenance3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)3+ years experience with Data ModelingExperience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)2+ years experience working with enterprise DE tools and experience learning in-house DE toolsBachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.Preferred Qualifications:Experience with more than one coding languageExperience designing and implementing real-time pipelinesExperience with data quality and validationExperience with SQL performance tuning and end-to-end process optimizationExperience with anomaly/outlier detectionExperience with notebook-based Data Science workflowExperience with AirflowExperience querying massive datasets using Spark, Presto, Hive, Impala, etc.Experience building systems integrations, tooling interfaces, implementing integrations for ERP systems (Oracle, SAP, Saleforce etc).About Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.",Not Applicable,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
19,Data Engineer,Edmunds,1 month ago,Over 200 applicants,"Edmunds offers flexibility to work fully remote, from our Edquarters, or a combination of bothAt Edmunds we’re driven to make car buying easier. Ever since we began publishing printed car guides in the 60’s, the company has been in the business of trust, innovating ways to empower and support car shoppers. When Edmunds launched the car industry’s first Internet site in 1994, we established a leadership position online and have never looked back. Now, as one of the most trusted review sites on the Internet, millions of visitors use our research, shopping and buying tools every month to make an easy and informed decision on their next car. For consumers, we bring peace of mind. For dealers, we make tools to help them solve their problems and sell more cars. How do we do it, you ask? The key ingredients are our enthusiastic employees, progressive company culture and cutting-edge technology. Want to join the team? Read on to find out how!What You’re Applying ForEdmunds is looking for a Data Engineer to help us manage the data explosion dilemma! You will be joining a strong, determined and results-oriented Data Engineering team that is transforming Edmunds from IT to real time data-driven. You will get hands-on experience solving complex data problems using Big Data frameworks and methodologies. You’ll be helping the company make real time decisions based on the torrent of data it receives, empowering analytics on existing products as well as providing insights on potential new opportunities for growth.What You’ll DoCreate and maintain scalable, maintainable and reliable data pipelines that process very large quantities of structured and unstructured data in both batch and real time.Enhance and maintain the data lakehouse that powers the core of the company’s decision making process.Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Collaborate with team members with a goal of improving personal knowledge of the systems, ensuring that code changes meet business goals and technology best practices.Regularly interact and collaborate with colleagues across functions and teams.Work with stakeholders including the Executive, Product, and Data teams to assist with data-related technical issues and support their data infrastructure needs. What You NeedExcellent problem solving, troubleshooting, and communication skills especially in a hybrid and remote environment.Desire to learn new technologies.Demonstrated ability to design and write maintainable software.Understanding of software engineering best practices, object oriented analysis & design, and design patterns & algorithms.Experience enhancing and evolving existing systems.Almost all of our codebase is in Scala and Python, but we only require that you have a high proficiency in at least one object oriented or functional programming language.A strong candidate will also have:Experience writing ETL Jobs and working with data at scale.Experience writing and maintaining real time / streaming data pipelines.Familiarity with some of the following: Spark, Scala, Python, AWS, Databricks, Airflow.Fluency in SQLOther nice to haves: Kubernetes, Machine Learning.The compensation range for this position is $109,900 - $191,815 per year. The base pay will take into account internal equity as well as job-related knowledge, skills, and experience among other factors. In addition, Edmunds offers full-time employees a comprehensive total rewards package including the benefits listed below.Edmunds PerksFlexible time off13 Paid HolidaysComprehensive Health Benefits (medical, dental, vision, life and disability)Flexible Spending Accounts (Employees) and Health Savings Accounts (Employee and Employer Contributions)401K Plan with company matching at 100%, up to 6% of eligible salary with immediate vestingStock purchase programCarMax vehicle discountUp to 4 months Paid Parental LeaveHeartCash matches employee donations to the causes that are important to them2 Days of Paid Time Off for time to dedicate to social impact causesFitCash covers a portion of gym or fitness activity feesWell being sessions and events such as yoga, meditation and walking challengesOn-going career development sessions and an annual learning eventPet insuranceSabbatical leaveEducation ReimbursementPre-tax spending accounts for qualified transportation expensesPlus a coffee bar, frozen yogurt and more!Working @ Edmunds.com:Employees think it’s a pretty great place to work and some pretty impressive publications think it is too: we have been recognized as one of the best places to work by the Fortune Magazine and Great Places to Work, LA Business Journal (for the last 6 years!), Computerworld, Built in LA and Inc. Magazine. We've also been identified as one of the best workplaces specifically in Technology and also for Diversity and Asian Americans. If you’re interested in learning more and joining our mission, we’d love to hear from you!Edmunds will consider for employment qualified candidates with criminal histories in a manner consistent with the requirements of all applicable laws.",Mid-Senior level,Full-time,Information Technology,Motor Vehicle Manufacturing,2024-05-12
20,Data Engineer,Xenon arc,1 week ago,Over 200 applicants,"About Xenon ArcAt Xenon arc, Inc. our vision is to redefine distribution by transforming the way producers go to market.Xenon arc serves a diverse range of clients, from billion-dollar companies specializing in industrial solvents and chemical products to major international food ingredients providers, all seeking to drive growth with difficult-to-serve customers, create business and working capital efficiencies, scale technical expertise, and embark on digital transformation.Our model is uniquely optimized to solve the challenges faced by our clients. Serving as an extension of their brand, we uphold the crucial client-to-customer connection. With trained, focused, and technically savvy teams, we drive sales and service to exceed expectations, use digital platforms to support customer engagement, and optimize distribution functions to alleviate operational pressures.Xenon arc is not just a distribution solution; we are a strategic partner committed to transforming the way businesses go to market and achieve lasting success.We are dedicated to creating a personal growth environment where team members are provided opportunities to advance their professional development and are encouraged to explore their passions. We invest in our culture to create a supportive environment that fosters team collaboration and creative problem solving.Xenon Arc is looking for a Data Engineer who is excited to solve business challenges through the application of data science and analytics.FLSA Classification ExemptReports toDirectorEssential Job DutiesDesign, code, test, and debug configuration of the data warehouse and business intelligence systems (PowerBI).Lead development and maintenance of PowerBI security, architecture, and data feeds.Integrate data with upstream and downstream applications through data pipelines and APIs.Collaborate with the cross-functional teams to define and document application requirements.Deliver projects on time by maintaining high code quality.Conduct code review sessions and prepare code for production deployments.Basic QualificationsBachelor’s degree in computer science, computer engineering, or related field1+ years of professional experience in software developmentExperience in data analytics and techniques, including proficiency in data visualization platforms like PowerBI and TableauProficiency in programming languages such as Python, R, and SQLProficiency in PowerBI developmentExperience working in Microsoft Azure environment is requiredUnderstanding of ETL and reverse ETL is a plusCritical thinking and attention to detail on the product that is developedBenefits:We offer competitive benefits: 100% paid medical, dental, and vision for employees, a 401k with company match, free parking options, and paid holidays, vacation & sick time! Location & CommitmentsFull-time, permanentReports to office HQ in Bellevue, WashingtonWork Schedule: 4 days in office, 1 day work from homePhysical DemandsMust be able to remain in a stationary positionMust be able to operate a computerTravel RequiredMinimal (up to 10%)Equal Employment Opportunity StatementIt is the policy of Xenon arc to grant equal employment opportunity to all applicants and employees without regard to race, color, national origin, ethnicity, marital status, parental status, disability, veteran status, age, religion, political affiliation, gender, sex, gender identity, or sexual orientation. It is the intent and desire of Xenon arc that equal employment opportunity will be provided in all phases of the employment relationship. Xa is a Title VII employer and strictly prohibits any type of discrimination or harassment based on any of the characteristics mentioned above. Employment opportunities and pay are and shall be open to all qualified applicants solely based on their experience, skills, and abilities.Other DutiesPlease note this job description is not designed to cover or contain a comprehensive listing of activities, duties, or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.",Associate,Full-time,Information Technology and Engineering,Chemical Manufacturing and Food and Beverage Manufacturing,2024-05-12
21,Data Engineer,Microsoft,2 weeks ago,Over 200 applicants,"The Azure Core Organization is responsible for creating the foundation of Microsoft’s Cloud Platform for utility computing. This platform is one of the lowest levels of the services software/hardware stack and includes an efficient, virtualized computational substrate, a fully automated service management system, and a comprehensive set of highly scalable storage services.The Azure Compute Capacity and Efficiency (AC2E) team is the team in Azure Core tasked with managing all aspects of Compute capacity and efficiency management across the fleet. Capacity Management needs to ensure that on the one hand, there is sufficient capacity across all regions, allocation domains, and hardware infrastructure to meet all customer demand, while on the other hand ensuring that capacity is provisioned efficiently thereby avoiding overspending and COGS/CAPEX impact. At the scale of Azure’s business, managing this trade-off across the entire Azure Compute fleet is an enormously complex task, where improvements can make the difference between customer allocation failures on the one hand, and gargantuan savings on the other.As a Data Engineer in the team, you will work closely with our software engineers, program managers, and data scientists across different teams within Azure Core. You will also collaborate with a variety of internal partner teams across Azure and Microsoft. You will build reliable, secured, highly scalable, performant data pipelines to enhance the Azure Compute allocation, deliver capacity management and efficiency improvements. The value of your work will be reflected in improvements to the Azure platform, Azure service capacity fulfillment rate, customer satisfaction, and various efficiency metrics, including COGS reduction. You will have opportunities for mentorship, accelerate your career growth, and work on truly high-business impact areas.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.In alignment with our Microsoft values, we are committed to cultivating an inclusive work environment for all employees to positively impact our culture every day.ResponsibilitiesData Engineering, insights generation and analytics with deep domain knowledge understanding.With detailed instructions, you’ll implement code to extract raw data, validate its quality, and ensure the correct data is ingested within your area of work after cooking, data transformation.You will follow data modeling and handling procedures to maintain compliance with all applicable laws and policies across your assigned workstreams.Integrating analytics intelligence into the Azure platformAdvocate for best practices in data engineering.OtherEmbody our Culture and ValuesQualificationsRequired Qualifications: Bachelor's Degree in Computer Science, or related field OR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Additional / Preferred QualificationsBachelor's Degree in Computer Science, Math, Software Engineering, Computer Engineering , or related field AND 1+ year(s) experience in business analytics, data science, data modeling or data engineering workOR Master's Degree in Computer Science, Math, Software Engineering, Computer Engineering, or related fieldOR equivalent experience.Experience in business analytics, data science, software development, data modeling OR data engineering work.Data Engineering IC2 - The typical base pay range for this role across the U.S. is USD $76,400 - $151,800 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $100,300 - $165,400 per year.Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here:https://careers.microsoft.com/us/en/us-corporate-payMicrosoft will accept applications and processes offers for these roles on an ongoing basis.#AzurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",Not Applicable,Full-time,Information Technology,Software Development,2024-05-12
22,Data Engineer Intern,People Tech Group Inc,2 weeks ago,Over 200 applicants,"Role: Data InternLocation: Redmond, WADuration: 3 months (Based on Performance & reporting manager feedback will get convert to FTE)Type of Internship: unpaid Job Overview:We are seeking a motivated and detail-oriented Data Engineering intern to join our dynamic team. This internship opportunity will provide hands-on experience in data management, ETL (Extract, Transform, Load) processes, and working with big data technologies.Job Responsibilities:Assist in designing, developing, and maintaining data pipelines and ETL processes.Collaborate with data scientists and analysts to understand data requirements and implement solutions.Develop and optimize database queries and data transformation workflows.Explore and implement technologies for data ingestion, storage, and processing.Ensure data quality and integrity through validation, testing, and troubleshooting.Work with various data sources including structured, semi-structured, and unstructured data.Learn and apply best practices in data engineering and data architecture.Requirements:Bachelors/master’s degree in computer science, Engineering, Data Science, or a related field (preferred).Strong understanding of databases, SQL, and data modeling concepts.Proficiency in at least one programming language (e.g., Python, Java, Scala) for data manipulation and scripting.Familiarity with data warehousing concepts and tools.Basic knowledge of big data technologies (e.g., Hadoop, Spark, Kafka) is a plus.Ability to analyze complex data sets and derive meaningful insights.Strong problem-solving skills and attention to detail.Good communication skills and ability to work in a team environment.Preferred Skills:Experience with cloud platforms for data storage and processing (e.g., AWS, Azure, Google Cloud).Knowledge of data visualization tools (e.g., Tableau, Power BI) for reporting and analysis.Understanding of machine learning concepts and algorithms.Previous internship or project experience related to data engineering or analytics.",Internship,Internship,Consulting,IT Services and IT Consulting,2024-05-12
23,Data Engineer,Tech Mahindra,4 days ago,Over 200 applicants,"We are looking for Strong Data Engineer with 6+ year’s experience.Required Skills: ADF pipelines, SQL, Kusto, Power BI, Cosmos (Scope Scripts). Power Bi, ADX (Kusto), ADF, ADO, Python/C#.Good to have – Azure anomaly Alerting, App Insights, Azure Functions, Azure FabricQualifications for the role 5+ years experience building and optimizing ‘big data’ data pipelines, architectures and data sets. Specific experience working with COSMOS and Scope is required for this role. Experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases is a plus. Experience with investigating and on-boarding new data sources in a big-data environment, including forming relationships with data engineers cross-functionally to permission, mine and reformat new data sets. Strong analytic skills related to working with unstructured data sets. A successful history of manipulating, processing and extracting value from large disconnected datasets.",Mid-Senior level,Full-time,"Engineering, Information Technology, and Other",IT Services and IT Consulting and Engineering Services,2024-05-12
24,Python Data Engineer + GCP,Zortech Solutions,3 days ago,,"Role: Python Data Engineer + GCPLocation: Austin TX (100% Onsite from Day 1) – (Visa Independent candidates preferred, we wanted to onboard candidates in next 2-3 weeks)Duration: Fulltime onlyJob DescriptionStrong focus on Python coding and software development. Develop programs for ETL/data processing in Python. Experience on GCP. Good to have experience on GCP Dataflow. Collaborate with cross-functional teams to understand project requirements and RequirementsBachelor’s or master’s degree in computer science, Engineering, or related field. Hands-on extensive experience with Python language and libraries. Experience on GCP. Good to have experience on GCP Dataflow. Have knowledge on ETL and Data Processing. Good to have knowledge on AI/ML. Excellent problem-solving skills and ability to think creatively to develop innovative solutions. Strong communication skills and ability to collaborate effectively with cross-functional teams. Preferred QualificationsStrong focus on Python coding and software development. Knowledge of cloud computing platforms GCP. Previous experience in industries such as healthcare, finance, or manufacturing.",Entry level,Full-time,Information Technology,Human Resources Services,2024-05-12
25,Data Engineer,Tapcheck,3 weeks ago,Over 200 applicants,"Tapcheck is looking for a Data Engineer to join our growing Data team. In this role you will partner closely with stakeholders to gather requirements and play a crucial role in shaping the future of Tapcheck's data infrastructure.What You'll Do:Collaborate with business stakeholders to gather and translate their requirements into actionable data solutionsDesign, develop, and maintain data pipelines using Azure Data Factory, with SQL queries as the primary transformation stepsImplement data quality checks to ensure data accuracy and consistencyPerform data analysis and reconciliation, supporting business users in their reporting needsUtilize Omni Analytics, our new BI tool, to build insightful reports and dashboardsContribute to the modern data stack and drive the migration towards a formal data warehouseWhat You'll Bring:3+ years of experience as a BI / data engineer, preferably in a smaller company or start-up environmentStrong attention to detail and ability to work with complex data setsProficiency in SQL, including the mastery of subqueries, CTEs, and window functionsExperience with data pipeline and ETL tools (Azure Data Factory, DBT, Fivetran)Familiarity with reporting and visualization tools such as Looker and Omni AnalyticsKnowledge of modern data warehousing concepts and dimensional modelingExcellent communication and interpersonal skillsThis is a remote-friendly role. Ideally, candidates will sit in the following states: AL, AZ, CA, CO, DC, DE, FL, GA, ID, IL, LA, MA, MO, NC, NH, NJ, NV, NY, PA, OR, OH, RI, SC, TX, VA, WA, WIAbout Tapcheck:Tapcheck is a digital platform offering an easy and convenient way to access on-demand earnings early. Available at no cost to employers, our app-based on-demand pay solution helps relieve the financial stress that many employees experience on a daily basis.The Tapcheck team is passionate about our mission to improve financial wellness and boost business productivity. By giving workers the ability to transfer wages they've earned directly to their bank account or pay card without waiting for payday, Tapcheck eliminates the need for high-interest payday loans or employer-funded cash advances.How We Get Things Done:Our core values act as a steadfast guide, directing our decisions and anchoring our actions. We consider these values non-negotiable, especially when it comes to our hiring process. Humility: We believe in the power of humility. We value team players who are down-to-earth, respectful, and open to learning from others. Our employees approach challenges with a positive attitude, acknowledging their strengths and weaknesses while celebrating the achievements of their colleagues Grit: We admire individuals with grit - those who demonstrate unwavering determination and resilience in the face of obstacles. At Tapcheck, we take pride in overcoming challenges together, pushing the boundaries of what is possible, and embracing failure as an opportunity for growth Raising the Bar: Continuous improvement is at the heart of our culture. We are committed to setting high standards and pushing ourselves to exceed them. We seek employees who are innovative and strive for excellence, constantly seeking ways to enhance our products, services, and processes Striving for Growth: We foster an environment that encourages personal and professional development. Our employees are driven to learn, grow, and adapt to new circumstances. We support individuals who take initiative, seek out new challenges, and actively contribute to their own growth and the growth of the companyWhy Join Tapcheck?Competitive basePaid Time OffHealth InsuranceDental InsuranceVision Insurance401K MatchCompensation: $105,000 - $115,000. The actual base salary will depend on numerous factors such as: location, experience, training, knowledge. and skills. Tapcheck reserves the right to amend, change, alter, and revise pay ranges and benefits offerings at any time. All applicants acknowledge that by applying to this position you understand that this specific pay range is contingent upon meeting the qualifications and requirements of the role, and for the successful completion of the interview selection and process. It is at the Company's discretion to determine what pay is provided to a candidate within the range associated with the role.Equal Employment Opportunity PolicyTapcheck, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
26,Data Engineer,University of Maryland Medical System,2 days ago,,"Company DescriptionThe University of Maryland Medical System is a 14-hospital system with academic, community and specialty medical services reaching every part of Maryland and beyond. UMMS is a national and regional referral center for trauma, cancer care, Neurocare, cardiac care, women’s and children’s health and physical rehabilitation. UMMS is the fourth largest private employer in the Baltimore metropolitan area and one of the top 20 employers in the state of Maryland. No organization will give you the clinical variety, the support, or the opportunities for professional growth that you’ll enjoy as a member of our team.Job DescriptionEnsure analytics infrastructure and associated systems meet business requirements and industry best practices.Gather and process raw data from multiple disparate sources (including writing scripts, calling APIs, write SQL queries, etc.) into a form suitable for analysis.Gathers, analyzes, documents and translates application requirements into data models.Builds data models.Enables big data, batch and real-time analytical processing solutions leveraging emerging technologies.Use python to design and execute data engineering pipelines Work with researchers to understand the requirements for data provisioning and then provision the data in a secure and governed fashionQualificationsBachelor’s degree in computer science, mathematics, information systems, engineering, physical sciences, life sciences or closely related field is required. Four (4) years of equivalent related professional experience may be substituted for education requirement. Additional certifications are preferred.Minimum two (2) years’ experience designing, implementing and supporting systems in a large scale analytics or data engineering environment containing many disparate application systems and multiple data sources is required.Proficiency is python is requiredKnowledge of Epic (Chronicles/ Clarity/ Caboodle) is a plusAdditional InformationAll your information will be kept confidential according to EEO guidelines.",Not Applicable,Full-time,Other,Hospitals and Health Care,2024-05-12
43,Data Engineer,Wider Circle,3 days ago,Over 200 applicants,"Overview:Data Engineers serve a unique and important role in daily operations at Wider Circle. Customer data is the bedrock of our business, and Data Engineering is responsible for laying the foundation for our success. Data Engineers work with internal and external stakeholders to gather, validate, clean and move data inside and outside the organization using technology and automation. Our data engineering team is also responsible for quality curation of data to ensure our productsYou will be joining a talented, fully remote Data Science, Engineering and Analytics team that handles a wide range of requests including customer data processing, weekly report automation, new product development and complex data integration.Company OverviewAt Wider Circle, we connect neighbors for better health. Wider Circle's groundbreaking Connect for Life® program brings neighbors together in-person and online for health, wellness, and social activities that improve mental and physical health. We create webs of community circles by employing local and culturally competent engagement specialists, whose hand-on-hand approach to forming trusted circles is informed by a sophisticated analytics platform. We are on a mission to make the world a better place for older adults and disadvantaged communities.ResponsibilitiesConceptualize data architecture (visually) and implement practically into logical structuresManage internal SLAs for data quality and frequencyAs a partner to data science and analytics provide modeled data for analysis and investigationSetting up data ingestion schemes of raw data into S3 and RedshiftExecuting automation to deploy data pipelinesProvide expert support for solving complex problems of data integration across multiple data setsPerforming testing of data after ingesting and database loadingUpdating and evolving our data ecosystem to streamline processes for maximum efficiencyRequirementsTechnical RequirementsExperience with AWS or similar (S3, Redshift, RDS, EMR) 3+ YearsStrong abilities with SQL & Python 3+ YearsExperience using API's for data extraction and updatingExperience with Git and version controlPreferred:Experience with Healthcare Data (Claims, CDAs/HRAs, Eligibility)Experience using Salesforce (Salesforce API)Matillion, Mulesoft or related toolingAirflow, cron or other automation toolsExperience working with Data Packages written in R or PythonExperience partnering with Data Scientists to optimize or productionalize modelsBenefitsAs a venture-backed company, Wider Circle offers competitive compensation, including:Performance-based incentive bonusesOpportunity to grow with the companyComprehensive health coverage, including medical, dental, and vision401(k) PlanPaid Time OffEmployee Assistance ProgramHealth Care FSADependent Care FSAHealth Savings AccountVoluntary Disability BenefitsBasic Life and AD&D InsuranceAdoption Assistance ProgramTraining and DevelopmentSalary $120,000-$140,000And most importantly, an opportunity to make the world a better place!Wider Circle is proud to be an equal-opportunity employer that does not tolerate discrimination or harassment of any kind. Our commitment to Diversity & Inclusion supports our ability to build diverse teams and develop inclusive work environments. We believe in empowering people and valuing their differences. We are committed to equal employment opportunity without consideration of race, color, religion, ethnicity, citizenship, political activity or affiliation, marital status, age, national origin, ancestry, disability, veteran status, sexual orientation, gender identity, gender expression, sex or gender, or any other basis protected by law",Mid-Senior level,Full-time,Information Technology,Non-profit Organizations and Primary and Secondary Education,2024-05-12
45,Junior Data Engineer,Team Remotely Inc,1 hour ago,Be among the first 25 applicants,"This is a remote position. Junior Data Engineer (1 year experience, remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match, we'll contact you directly. No guarantee of immediate placement, and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Databricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
27,Data Engineer,FinThrive,1 week ago,Over 200 applicants,"What you will doBuild a highly functional and efficient Big Data platform that brings together data from disparate sources and allow FinThrive to design and run complex algorithms providing insights to healthcare business operationsBuild ETL Data Pipelines in Azure Cloud using Azure ADF and DatabricksBuild Spark Streaming and Near Real Time applicationsPartner with internal business, product, and technical teams to analyze complex requirements and deliver solutionsParticipate in development, automation, and maintenance of application code to ensure consistency, quality, reliability, scalability, and system performanceDeliver data and software solutions working on Agile delivery teams  What you will bringBachelor’s degree in computer science or a related discipline 1+ years of data engineering in an enterprise environment 1+ years of experience writing production code in Python, PySpark or Scala Strong coding experience in at least one programming language. Python preferred.Experience with Big Data technologies in the Cloud such as Spark, Databricks, Hive, Sqoop, or any other equivalent components. Azure preferred.Experience with any Streaming applications such as Kafka, Spark Streaming, Azure Event HubExperience in having built and deployed to Production reasonably complex ETL Data Pipelines. Experience working with git and CI/CD tools Proven background in Distributed Computing, ETL development, and large-scale data processing  What we would like to seeExperience within healthcare field in a similar roleProficiency in SQL and query optimization Experience in Azure PowerShellExperience with Azure ADF, Azure Databricks.Experience with SQL Server. Preferred but not required.Experience with CI/CD, DevOps.Knowledge and passion for software development – including software architecture, functional and non-functional aspects",Mid-Senior level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
28,Jr. Data Engineer,LinkTMS,6 days ago,Over 200 applicants,"Role: Jr. Data EngineerDuration: Long TermLocation: Charlotte, NC, Onsite Description: In this contingent resource assignment you may: Participate in low to moderately complex initiatives and identify opportunity for process improvements within Database Engineering. Review and analyze basic or tactical Database Engineering assignments or challenges that require research evaluation and selection of alternatives related to low-to-medium risk deliverables. Present recommendations for resolving low to moderately complex situations and exercise some independent judgment while developing understanding of function policies procedures and compliance requirements. Provide information to client personnel in Database Engineering. Required Qualifications: 2 years of Database Engineering experience or equivalent demonstrated through one or a combination of the following: work or consulting experience training military experience education.Skills: Category: Areas of Expertise, Name: Data Warehousing, Required: Yes, Experience: 1; Category: Technical Skill, Name: ETL, Required: No, Experience: 2; Category: xms-USIT, Name: Data Analytics, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Engineer, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Integration, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Mapping, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Reporting, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Visualization, Required: Yes, Experience: 1; Category: xms-USIT, Name: Data Warehouse, Required: Yes, Experience: 1; Category: xms-USIT, Name: data pipelines, Required: No, Experience: 1Comments: This position is critical for creating a consistent Operating model across Teradata ETL and Hadoop in the areas of roadmap creation and tracking technology refresh planning consumption analysis and future hardware and software forecasts. This will also help improve our Vulnerability Remediation and Tech Refresh cycles, hence improving our Risk Management. The additional resource is needed to expand the scope of roadmap creation and tracking beyond Teradata to ETL and Hadoop as well. As a result, the scalability and stability of our platforms will be better managed. Familiarity with Infrastructure Management Database Management and experience with platforms like Teradata Hadoop ETL Technologies Ab Initio Informatica is desired along with sound understanding of industry best practices.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
29,Data Engineer,Steneral Consulting,3 weeks ago,Over 200 applicants,"100% RemoteNeed LinkedInW2 candidates onlyNeed only 2 strong candidatesThere will be a short tech assessment on this role which needs to be completed and cleared to be consideredSkills Requirement | Success Criteria for all:Hyper communication and transparencyDrivers with high level of self-motivationExtreme accountability and ownershipHands-on executionists vs theoristsCritical thinking and problem-solving skillsSkills Requirement | Success Criteria for Data Engineer: Must be hands-on with development and build. Need team members who are self-motivated and driven.Must have deep experience with SSIS, Python, SQL, and ideally Azure and Azure Data Factory. Primary relevant experience would be coding complex SQL, building the integration packages (including logic development), flat file transfers, etc. There is no XML work and no experience needed with Pyspark, Spark, or any other big data platforms. The standard requirement is Rest or Soap-based APIs but the majority are flat files. There may be some ETL work moving data from various source systems to data warehouse.",Mid-Senior level,Contract,Information Technology,Software Development,2024-05-12
30,Data Engineer Intern,Tencent,1 week ago,Over 200 applicants,"Responsibilities:Tencent Games was established in 2003. We are a leading global platform for game development, operations and publishing, and the largest online game community in China. Tencent Games has developed and operated over 140 games. We provide cross-platform interactive entertainment experience for more than 800 million users in over 200 countries and regions around the world. Honor of Kings, PUBG MOBILE, and League of Legends, are some of our most popular titles around the world. Meanwhile, we actively promote the development of esports industry, work with global partners to build an open, collaborative and symbiotic industrial ecology, and create high-quality digital life experiences for players.ResponsibilitiesYou will be responsible for the raw data pipeline for all Tencent oversea games. You will be expected to effectively partner with upstream engineering teams and downstream consumers, including data analysts, data scientists and ML engineers. Requirements:Minimal 1-2 years of technical experience designing, building, and maintaining distributed data processing platforms. Minimal 1-2 years of industry experience working with batch or streaming distributed data processing technologies. e.g. Hadoop, MapReduce, Spark, Flink, Kafka, Presto, etc. for building efficient & large-scale data pipelines. Minimal 1-3 years of data modeling experience designing data warehouse table schemas and logging schemas. Proficiency in at least one high-level programming language (Java, Scala, Python, Go or equivalent). Experience with large, complex, highly dimensional data sets; hands-on experience with SQL. Experience working with cross-functional teams to collect business requirements, build consensus, and manage expectations. You are self-directed and capable of operating amidst ambiguity. You are humble, continually growing in self-awareness, and possessing a growth mindset. You are curious and have excellent written and verbal communication as well as problem-solving skills.",Internship,Full-time,Information Technology and Engineering,Software Development,2024-05-12
44,Data Engineer,OncoHealth,2 weeks ago,Over 200 applicants,"About OncoHealthOncoHealth is a leading digital health company dedicated to helping health plans, employers, providers, and patients navigate the physical, mental, and financial complexities of cancer through technology enabled services. Supporting more than 8 million people in the US and Puerto Rico, OncoHealth offers digital solutions for treatment review and virtual care across all cancer types.About The RoleThe Data Engineer is primarily responsible for the development and maintenance of data products and pipelines which support OncoHealth’s OneUM and Iris offerings. This role participates in cross-functional projects, design, and implements scalable data solutions.Participates in data engineering efforts within the enterprise data and analytics team to provide data pipeline and platform development and maintenance utilizing engineering best practices, CI/CD, and test-driven development in an Agile environment Implement modern data pipelines supporting healthcare technical services on public cloud (Python, Databricks, SQL Server, Azure, Airflow)Deliver innovative data solutionsDevelopment and support of all data systemsParticipate in production and incident management for OneUM and IrisCollaboratively work with functional leadership, business users, and engineers across the organization to develop data products, identify and track key milestones, and implement solutions to enable data and drive culture Partner with DevOps, security, compliance, and technical teams in multiple lines of business to create innovative technical solutions within OncoHealth’s product offeringsCollaborate with business users, clients, and vendors to translate complex business requirements into data solutionsCoordinate with data governance and data architects to create maintainable and scalable solutionsAbout YouBachelor’s degree or relevant experience required2-4 years of data engineering experience or relevant educational attainment requiredThe ideal candidate projects high energy, possesses a passion for state-of-the-art technology, and enjoys finding solutions to complex data problems.Experience creating and managing technical data products in support of enterprise initiatives.Demonstrated ability to analyze complex business needs and recommend practical business solutions is required.Familiarity with healthcare data and ontologies including claims, eligibility, provider, and clinical data sets is preferred. Candidate must be an active Python and SQL developer.The ideal candidate will have demonstratable experience using technologies such as Databricks, Airflow, ADF, and data warehousing as part of ETL and other enterprise data solutions. Nice to have experience with event driven architectures and APIs. Python, SQL, NoSql, Pyspark, Spark SQL, Databricks, Azure cloud-native tools, Data Warehouses, Orchestration (Airflow), Kafka.About the LocationOncoHealth is committed to remote, hybrid or in office work options. The majority of the team will be remote or in hybrid work arrangements with offices in Atlanta, GA and Guaynabo, PR. We are open to employees nationwide but work primarily in the Eastern and Central Time Zones.Our CultureTaking ownership of quick action, critically thinking through the needs, and working well with others are key competencies of team member success. Our leadership is dedicated to building a culture based on respect, clinical excellence, innovation – all with a focused mission of putting patients first!We offer a full benefit package on your first day, along with a company bonus. You may visit or work from our very modern and engaging offices, and experience a fun, collaborative environment where social activities and community events matter. We enjoy being together!OncoHealth is committed to providing an environment of mutual respect where equal employment opportunities are available to all applicants and team members without regard to race, color, religion, marital status, age, national origin, ancestry, physical or mental disability, medical condition, pregnancy, genetic information, gender, sexual orientation, gender identity or expression, veteran status, or any other status protected under federal, state, or local law. All employment decisions are based on qualifications, merit, and business need.The OpportunityThe cost of cancer related medical services and prescription drugs in the United States is expected to reach $246 billion by 2030. OncoHealth has enjoyed rapid growth over the past 3 years and seeks smart, collaborative people to join its team. We have just under 250 team members, so we can move swiftly but precisely to the market needs of our customers. Strongly backed financially by Arsenal Capital Partners & McKesson Corporation, we remain in an investment and growth mode. This means we are open-minded to how we get the work done – now is the perfect time to talk to us!Our Current SolutionsThrough the use of OncoHealth's utilization management system, OneUM, our customers can use a single e-Prior Authorization portal for all oncology drug request and treatments. Our system improves quality of care, reduces provider abrasion and gives health plans visibility into the total cost of oncology treatment.OncoHealth offers Oncology Insights Pro, an analytic software solution that enables health plans to use data and analytics to improve oncology programs. Using real world data, our engineers normalize data to create analytic dashboards with drill down compatibilities. The data is the paired with expert guidance providing the strategies an insight needed to keep up with the continuing evolving cancer treatment landscape.OncoHealth offers Pharmacy Consulting services to health plans and pharmaceutical companies. New cancer treatments are entering the market at an unrelenting pace. Since 2018, the FDA approved 121 new cancer applications including 49 novel cancer drug entities. Our Board-Certified Oncology Pharmacologists can help health plans update drug policies, offer utilization management and formulary advice, and development training for staff.OncoHealth's latest offering is Iris, a digital telehealth platform that delivers personalized, oncology-specific support to navigate the physical symptoms and emotional challenges caused by cancer and cancer treatment. Powered by technology, staffed 24X7, and delivered with empathy, Iris allows patients to connect with trained oncology experts and receive personalized, oncology-specific telehealth support.",Entry level,Full-time,Information Technology,Hospitals and Health Care,2024-05-12
31,Data Engineer (Remote),Belk,2 weeks ago,Over 200 applicants,"EDW Data Engineer is responsible for designing, maintaining, and optimizing data infrastructure for data collection, management, transformation, and access. Creates pipelines that convert raw data into usable formats for data scientists and other data consumers to utilize. Builds and leverages information loaded into the Belk Enterprise Data Warehouse (EDW) environment. Responsible for developing and overseeing processes that support data environments. Responsible for interpretation of information in these environments and validating this data with the source data environments. Plays a role in Agile planning, providing advice and guidance, and monitoring emerging trends.Job Functions Design and implement database solutions to store, secure and effectively use enterprise data. Implement process improvements and tuning measures to ensure data availability and integrity. Understand and action data relationship within, and across, different Data environments Engage well with IT and business teams that leverage EDW. Drive alignment between data architecture and business needs. Partner with business users and data scientists in the organization to ensure data availability and help increase speed and accuracy of decision making. Learn new technologies and adapt to changing environments and priorities. Maintain necessary controls to ensure data security and integrity Design, develop, and maintain data pipelines in Snowflake for data ingestion, transformation, and loading from various sources into Snowflake and enable effective reporting out of that data.Minimum Education & Experience: Bachelor's degree in computer science, related field, or equivalent experience 5+ years of experience as Data Engineer Working experience with data-oriented applications from conception and design to implementation and support Experience with data related research and problem resolution Experience with database technology including cloud database experience. Proven experience in data engineering roles with a focus on Snowflake and Python Retail domain experience is preferred.Knowledge & Skills Extensive knowledge of database environments Extensive experience in data modeling and design in databases such as Oracle, Teradata, and Snowflake. Experience with SQL on RDBMS databases Experience in programming languages like Python or any other scripting languages is necessary Knowledge of reporting tools like MicroStrategy and Tableau#IND3",Entry level,Full-time,Information Technology,Retail,2024-05-12
32,"Data Engineer, Python / AWS",Credera,2 days ago,,"REMOTE ROLE for Contractor anywhere in N. America ** 12 month contract and possible extension ** Rate = $65 - 80/hr USD Based On Experience Description:Data Engineers at TA Digital work closely with Subject Matter Experts (SMEs) to design the ontology (data model), develop data pipelines, and integrate Foundry with external systems containing the data. Data engineers also need to provide guidance and support on how to access and leverage the data foundation to create new workflows or analyze data.Responsibilities Include:Leverage Generative AI on AWS data Integrate new data sources to Foundry using Data Connection Implement 2-way integrations between Foundry and external systemsDevelop pipelines transforming tabular or unstructured dataImplement data transformations in PySpark / PySpark SQL to derive new datasets or create ontology objects Set up support structures for pipelines running in productionMonitor and debug critical issues such as data staleness or data qualityImprove performance of data pipelines (latency, resource usage)Design and implement an ontology based on business requirements and available dataProvide data engineering context for application developmentRequirements:Generative AI on AWS such as Amazon Bedrock, Amazon SageMaker, Amazon EC2, Amazon EC2 UltraClusters, AWS Trainium or AWS InferentiaPython – complete language proficiency SQL – proficiency in querying language (join types, filtering, aggregation) and data modeling (relationship types, constraints)PySpark – basic familiarity (DataFrame operations, PySpark SQL functions) and differences with other DataFrame implementations (Pandas)Distributed compute – conceptual knowledge of Hadoop and Spark (driver, executors, partitions)Databases – general familiarity with common relational database models and proprietary instantiations, such as SAP, Salesforce etc.Git – knowledge of version control / collaboration workflows and best practicesIterative working – familiarity with agile and iterative working methodology and rapid user feedback gathering conceptsData quality – best practices",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
33,Data Engineer,"Senseye, Inc.",4 days ago,,"We are seeking a skilled Data Engineer to join our team and play a pivotal role in developing and maintaining our data infrastructure. The ideal candidate will have a strong background in data management, analytics, and software development, with a focus on ensuring the integrity, reliability, and accessibility of healthcare data. This position offers an exciting opportunity to collaborate with cross-functional teams and contribute to the development of cutting-edge medical device software.Responsibilities:Design, develop, and maintain scalable data pipelines and ETL processes to support data extraction, transformation, and loading from various sourcesCollaborate with data scientists, software engineers, and domain experts to understand data requirements and implement solutions that address business needsEnsure the security, privacy, and compliance of healthcare data in accordance with regulatory requirements such as HIPAAOptimize database performance and query efficiency to enable real-time and batch data processingDevelop a data dashboard for use tracking incoming data and any quality issues that may ariseStay informed about emerging technologies and best practices in data engineering and contribute to continuous improvement initiativesRequirementsBachelor's or Master's degree in Computer Science, Engineering, or a related fieldProven experience in data engineering, with proficiency in Python, SQL, and/or other programming languagesFamiliarity with cloud platforms such as AWS, Azure, or Google Cloud PlatformProven experience in data visualization and data dashboard creation and maintenanceExcellent communication skills and ability to collaborate effectively in a cross-functional team environmentExperience in the clinical research, healthcare, or medical device industry is a plusHiring Process Applications will close 5/24 Will reach out for next steps interview by 5/28 First step is a phone screening Followed by two interviews with Senseye team members Additional interviews as needed Our target is to send an offer letter by 6/3BenefitsThe freedom and trust to define your role as we design, build, and ship our productsCompetitive salary and stock option planFlexible paid time off (vacation, sick leave, and public holidays)Flexible schedulesCompany health care planMedical, dental, and vision insuranceShort and long term disability insuranceLife insurance policy401kCommuter benefits for parking, public transit, carshares, etcMothers' roomFully stocked kitchenOpportunities for continuing educationDid you know that often women apply for open jobs only if they think they meet 100 percent of the criteria listed? Men will apply to that same posting if they feel they meet 60 percent of the requirements.We know that not everyone comes from the same background, has had the same experiences, or education, and we wouldn't want it any other way. Don't worry about checking every single box, instead we want you to bring your own unique outlook to the team, whatever that might be!",Associate,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
34,Junior Data Engineer,HireMeFast LLC,13 hours ago,,"This is a remote position. DISCLAIMER:  This job posting is intended for active pooling of candidates who will become part of our talent pool. Your qualifications will be assessed against both current and future job openings. Should your application align with a role that corresponds to your skills and experience, and an opportunity arises, our recruitment team will reach out to you immediately. Please note that this does not guarantee immediate placement or contact. Additionally, we exclusively consider applications from individuals who are currently reside in the US/Canada during their application process. Salary: $60,000 - $70,000 per annum Experience Required:  Minimum 1 year of project experiencePosition SummaryJoin the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulations Create/maintain documentation for data processes, data flows, and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach, share knowledge, and work with others to make the team successful. Communication: Exceptional verbal, written, organizational, presentation, and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python, Java, SQL 2+ years of experience with ETL tools and database management (relational, non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment, data cleansing, and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark, Data bricks, and Azure Synapse. EducationBachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience",Mid-Senior level,Full-time,Information Technology,Software Development,2024-05-12
35,Data Engineer,Analytica,1 week ago,Over 200 applicants,"Analytica is seeking a remote Data Engineer (MLOps) to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization. Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.   Responsibilities include (but not limited to):  Build out data pipelines in AWS for data lakes and data warehousesimplementing data pipelines, via a variety of tools including Amazon S3, AWS Glue, Amazon Textract, Amazon Comprehend, AWS Lambda, SQL and/or Python scripts, in the cloud to an existing data lake and data warehouseImplement data pipelines, for batch and streaming data sources, from external feeds into a cloud-based data lake and eventually into data warehouses; Implement data cataloging to share metadata information for datasets in the data lake;Use AWS serverless components in the data pipeline architecture;Use IaC tools to deploy the pipelines within AWS Basic Qualifications:  5+ years of hands-on Data Integration experience creating and maintaining efficient scripts/data pipelines to clean, transform and ingest data from a variety of formats into database tables, data warehouses or data lake repositories Experience building data pipelines using AWS serverless components; using AWS Glue to build, maintain and monitor ETL jobs; using Python to implement ETL scripts and AWS Secrets Manager to manage credentialsExperience with AI/ML, NLP, Sentiment Analysis, etc. with one of the leading cloud providers is a plusAWSS ML Certification or AWS Data Engineer Certification is desiredMust be US CitizenMust be able to obtain and maintain a Public Trust security clearanceAbout Analytica:Analytica LLC. is an Equal Employment Opportunity and Affirmative Action employer. We value diversity at all levels. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to sex, pregnancy, race, religion or religious creed, color, gender, gender identity, gender expression, national origin, ancestry, physical or mental disability, medical condition, genetic information, marital status, registered domestic partner status, age, sexual orientation, military or veteran status, protected veteran status, or any other basis protected by federal, state, local law, ordinance, or regulation and will not be discriminated against on these bases.Powered by JazzHRqr39UOtyE1",Mid-Senior level,Full-time,Information Technology,Internet Publishing,2024-05-12
36,Data Engineer,Worth AI,1 week ago,Over 200 applicants,"Worth AI, a dynamic player in the computer software industry, is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity, diversity, and inclusion. With core values centered around diversity of thought, teamwork, and adaptability, Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI, you will play a crucial role in designing and implementing data pipelines, data integration solutions, and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists, software engineers, and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing, data modeling, and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign, build, and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest, transform, and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role, preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling, data warehousing, and database design principlesStrong programming skills in Python, SQL, and other relevant languagesExperience with relational and NoSQL databases, such as PostgreSQL, MySQL, MongoDBProficiency in data integration and ETL tools, such as Apache Kafka, Apache Airflow, or InformaticaFamiliarity with big data processing frameworks, such as Hadoop, Spark, or FlinkKnowledge of cloud platforms, such as AWS, Azure, or GCP, and experience with data storage and processing services in the cloudUnderstanding of data governance, data privacy, and data security best practicesStrong problem-solving and troubleshooting skills, with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing, processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical, Dental & Vision)Retirement Plan (401k, IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando, FL)Wellness Resources",Mid-Senior level,Full-time,Engineering,Non-profit Organizations and Primary and Secondary Education,2024-05-12
37,"Data Engineer, Internal Audit Data Analytics",Amazon,3 days ago,,"DescriptionInternal Audit’s mission is to help our businesses improve controllership, operational efficiency, and customer experience.Amazon is seeking a Data Engineer for our Internal Audit Data Analytics team to provide data analytics services and solutions to enable our audit programs to scale with Amazon’s growth and complexity. This is an opportunity to provide custom-build solutions and services that will increase the productivity of Amazon’s audit function using data.In this role, you will be a technical expert with a scope that spans all of Amazon’s Consumer businesses, Amazon Web Services, and Amazon subsidiaries. You will work closely with the engineers , scientists, and auditors in our organization to improve resiliency and quality of the data in our environment. You will be an expert in sourcing semi-structured and complex data types and normalizing them into a consumable data models that are accessible to business users. Our team maintains an infrastructure that supports changing data needs. This requires data engineering problem solving to build high quality, reliable, accurate, consistent, and architecturally sound data solutions that are aligned with our business objectives.Key job responsibilitiesData Engineers spend their days balancing customer requests and operational excellence. This data engineering role will work to add new data to the data lake, make existing data more useful, and support infrastructure projects. Data Engineers are expected to be on the team's oncall rotation where pressing issues can be addressed.A day in the lifeData Engineers spend their days balancing customer requests, operational excellence, and making improvements to the core infrastructure. This data engineering role will work to add new data to the data lake, make existingAbout The TeamInternal Audit's Data Analytics team has 3 core subgroups: Data Engineering, Data Science, and Audit Support. This role will be within the Data Engineering subteam but will frequently work with other individuals within Internal Audit. The Data Engineering team's primary tech stack is based on AWS with a large focus on a Redshift centric Data Lake.We are open to hiring candidates to work out of one of the following locations:Seattle, WA, USABasic Qualifications Experience with SQL Experience with data modeling, warehousing and building ETL pipelines Experience with one or more scripting language (e.g., Python, KornShell) 1+ years of data engineering experiencePreferred Qualifications Knowledge of AWS Infrastructure Experience with big data technologies such as: Hadoop, Hive, Spark, EMRAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Company - Amazon.com Services LLCJob ID: A2636921",Not Applicable,Full-time,"Finance, Information Technology, and Accounting/Auditing",Software Development,2024-05-12
38,Data Engineer II,Strava,3 weeks ago,Over 200 applicants,"About This RoleStrava is the leading digital community for active people with more than 120 million athletes, in more than 190 countries. The platform offers a holistic view of your active lifestyle, no matter where you live, which sport you love and/or what device you use. Everyone belongs on Strava when they are pursuing an active life.We are seeking data engineers to join our Data Platform team. Our vision is that key decisions and product at Strava can be greatly enriched with data to benefit athletes and the business. Our mission is to build and support a platform that enables access to data through self-service and extensible tools.This means we listen to all corners of the company for opportunities where data can make a difference. We distill this down and use modern technologies to develop both generalized and special-purpose data solutions.For more information on compensation and benefits, please click here.This is a hybrid role based in our San Francisco office.You’re excited about this opportunity because you will:Collaborate with people across teams and functions that hold deep curiosity for data.Work with hefty data systems at the global scale of Strava.Deliver value more through software, leaning into tooling and automation rather than repetitive toil.Grow your expertise in the steadily evolving technologies and ecosystem of data.You will be successful here by:Holding empathy for the users of our platform to truly understand the challenges we tackle for them.Fostering an inclusive and motivating team culture to help everyone achieve their best.Caring about high quality and reliable code, but also the end user experience.Solving problems efficiently, creatively, and completely despite constraints in time or resources.Understanding how critical it is we maintain a high bar of data security and privacy.We’re excited about you because you:Have the ability to adapt and apply evolving data technologies to business needs (which means the list of bullets below will change over time!).Have developed software using programming languages like Python, Scala, Java, Go, Ruby, etc.Have sufficient familiarity to understand SQL queries in the context of data pipelines (i.e. dbt).Have experience with distributed data tools (i.e. Spark, Flink, Kafka) on large datasets.Have worked with cloud-data warehouses (i.e. Snowflake, BigQuery, Redshift) or other warehousing solutions.Have an understanding of underlying infrastructure needed to serve production services (i.e. Kubernetes, AWS, GCP, Azure).About StravaStrava is Swedish for “strive,” which epitomizes who we are and what we do. We’re a passionate and committed team, unified by our mission to connect athletes to what motivates them and help them find their personal best. And with billions of activity uploads from all over the world, we have a humbling and audacious vision: to be the record of the world’s athletic activities and the technology that makes every effort count.Strava builds software that makes the best part of our athletes’ days even better. And just as we’re deeply committed to unlocking their potential, we’re dedicated to providing a world-class, inclusive workplace where our employees can grow and thrive, too. We’re backed by Sequoia Capital, Madrone Partners and Jackson Square Ventures, and we’re expanding in order to exceed the needs of our growing community of global athletes. Our culture reflects our community – we are continuously striving to hire and engage diverse teammates from all backgrounds, experiences and perspectives because we know we are a stronger team together.Despite challenges in the world around us, we are continuing to grow camaraderie and positivity within our culture and we are unified in our commitment to becoming an antiracist company. We are differentiated by our truly people-first approach, our compassionate leadership, and our belief that we can bring joy and inspiration to athletes’ lives — now more than ever. All to say, it’s a great time to join Strava!Strava is an equal opportunity employer. In keeping with the values of Strava, we make all employment decisions including hiring, evaluation, termination, promotional and training opportunities, without regard to race, religion, color, sex, age, national origin, ancestry, sexual orientation, physical handicap, mental disability, medical condition, disability, gender or identity or expression, pregnancy or pregnancy-related condition, marital status, height and/or weight.We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.California Consumer Protection Act Applicant Notice",Entry level,Full-time,Information Technology,Software Development,2024-05-12
39,"Data Analytics Engineer, YouTube",Google,3 days ago,Over 200 applicants,"Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.Minimum qualifications:Bachelor's degree or equivalent practical experience. 3 years of experience coding in one or more programming languages.3 years of experience designing data pipelines, and dimensional data modeling for synch and asynch system integration and implementation using internal (e.g., Flume, etc.) and external stacks (DataFlow, Spark, etc.).3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.Preferred qualifications:Master’s degree in a quantitative field (e.g., Computer Science, Engineering, Statistics, Math).Experience with data warehouses, distributed data platforms, and data lakes.Ability to navigate ambiguity and work in a fast-moving environment with multiple stakeholders.Ability to break down multi-dimensional problems.Excellent business and technical communication, organizational, and problem-solving skills.About the jobYouTube has grown into a global community where people all over the world access information, share videos, and build culture. The YouTube team helps creators build careers, artists and Media Companies reach audiences, create products like YouTube Kids, YouTube Music, and YouTube TV, and engages communities around shared passions and global conversations.The YouTube Go-To-Market team is responsible for driving all Go-To-Market functions for the YouTube Business Organization including strategy and business operations, analytics and data science, partnership enablement, and product activation.At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesConduct requirements gathering and project scoping sessions with subject matter experts, business users, and executive stakeholders to discover and define business data needs.Design, build, and optimize the data architecture and Extract, Transform, and Load (ETL) pipelines to make them accessible for Business Data Analysts, Data Scientists, and business users to enable data-driven decision-making.Work with analysts to productionlize and scale value-creating capabilities including data integrations and transformations, model features, and statistical and machine learning models.Drive standards in data reliability, data integrity and data governance, enabling accurate, consistent, and trustworthy data sets, business intelligence products, and analyses.Engage with the analyst community, communicate with analysts to understand user journeys and data sourcing inefficiencies, advocate best practices, and lead analyst training.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",Not Applicable,Full-time,"Project Management, Consulting, and Engineering","Information Services and Technology, Information and Internet",2024-05-12
40,Data Engineer II,IntePros,3 weeks ago,Over 200 applicants,"Compensation Range:$45.00 - $53.00/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data Engineer IIIIntePros is looking for a Data Engineer, to work 3 days a week on-site and 2 days a week remotely for a team located in Bellevue, WA. This is an exciting opportunity that will work with various tools and technologies automating manual tasks to reduce operational burden on business teams.Responsibilities:Work in a complex data warehouse environment. Developing and supporting analytic technologies. Design, implement, and support an analytical infrastructure providing ad-hoc access to large datasets and computing power. What are the top three MUST HAVE skill sets (technical) that are required?3+ years of Data Engineering experience. Strong SQL Skills Strong Python Skills What are the top three PREFERRED skill sets (technical)?AWS technologies like redshift, S3, AWS Glue, EMR, etc. BI report development experience. Soft Skill requirements (team fit/personality requirements)Effective communication skills Strong MS Excel skills Data analysis skills",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
41,Data Engineer - Trading Analytics,Swish Analytics,2 weeks ago,Over 200 applicants,"Company OverviewSwish Analytics is a sports analytics, betting and fantasy startup building the next generation of predictive sports analytics data products. We believe that oddsmaking is a challenge rooted in engineering, mathematics, and sports betting expertise; not intuition. We're looking for team-oriented individuals with an authentic passion for accurate and predictive real-time data who can execute in a fast-paced, creative, and continually-evolving environment without sacrificing technical excellence. Our challenges are unique, so we hope you are comfortable in uncharted territory and passionate about building systems to support products across a variety of industries and consumer/enterprise clients.Job DescriptionSwish Analytics is seeking a Data Engineer to support our Trading Analytics team. The person in this role will ensure that client data is accurately ingested and reported to key stakeholders. They will work closely with the Trading team and Software Engineering team to troubleshoot client streams and monitor the accuracy of results in real-time. We're a team passionate about accurate predictions and real-time data, and hope you find satisfaction in building new products with the latest and greatest technologies. This is a remote position.Duties:Advance data engineering aspects of Trading Analytics, enabling faster and better trading decisions and reducing the reliance on manual reportingLead Trading team and customer based reporting, as well as on-demand data needs for Swish.In conjunction with Trading Analytics Manager, the Data Engineer will develop impactful and accurate reports, dashboards, and other data visualizations.Maintain data integrity and ongoing quality of delivered reports.Identify data quality issues and work with Data Science, Data Engineering, and Software Engineering teams to resolve challenges.Integrate large, complex real-time datasets into new consumer and enterprise products.Develop production-level predictive analytics into enterprise-grade APIs.Contribute to the implementation of fully-automated sports data delivery frameworks.Requirements:BS degree or higher in Computer Science, Data Science, Data Analytics or similar majorMinimum of 1 year of experience writing production level code.Proficiency in Python (pandas, NumPy).Proficiency in SQL (preferably MySQL).Experience utilizing REST APIs.Experience in SQL database management, shema design, index structuring.Experience with version control (git), continuous integration and deployment, shell scripting, and cloud-computing infrastructures (AWS).Experience with web scraping and cleaning unstructured data.Knowledge of data science and machine learning concepts.Swish Analytics is an Equal Opportunity Employer. All candidates who meet the qualifications will be considered without regard to race, color, religion, sex, national origin, age, disability, sexual orientation, pregnancy status, genetic, military, veteran status, marital status, or any other characteristic protected by law. The position responsibilities are not limited to the responsibilities outlined above and are subject to change. At the employer's discretion, this position may require successful completion of background and reference checks.",Entry level,Full-time,Information Technology,"Technology, Information and Internet",2024-05-12
42,Data Engineer (NYC),Oakridge Staffing,1 week ago,Over 200 applicants,"Global hospitality company is looking for an experienced Data Engineer for their Midtown NYC headquarters. Responsibilities:Lead the in-house development of ETL/ELT data pipelines and data science projects.Create and own data products, such as a recommendation engine or predictive model.Provide key insights and analyses to senior stakeholders and executives.Work with the Data Engineering team to design and develop data models.Qualifications And Requirements5+ years of relevant professional experience in building AWS big data pipelines using Apache Spark.Strong hands-on experience with programming in Python.Expertise in SQL and analytical data modeling.Hands-on experience in pipeline orchestration tools, like Apache Airflow.Experience in PostgreSQL, Redshift, S3, AWS Lambda, Kinesis and Athena.Previous work with cloud-based BI tools (such as Looker, and Quicksight) is a plus.Strong organizational, problem-solving, and communications skills (must be able to do basic technical writing)",Mid-Senior level,Full-time,Engineering,Hospitality,2024-05-12
46,Data Engineer (ETL),INSPYR Solutions,1 week ago,Over 200 applicants,"Title: Data Engineer (ETL)Location: RemoteDuration: initial 6 monthsWork Requirements: US Citizen, GC Holders or Authorized to work in USJob Description: To design, develop, implement and maintain new IT solutions, or changes/enhancements to existing solutions that align with business initiatives and corporate strategies.This role will work with product owners and multiple internal and external teams to develop automated data pipelines from heterogeneous sources, including file and data validation, exception handling and reporting, and applying business rules in ETL to populate a repository in alignment with standards and guidelines.Recognized as an expert with specialized depth and breadth of expertise in their discipline. Solves complex problems, taking a broad perspective to identify solutions.Requires advanced proficiency in Python and SQL programming, as well as several years of hands-on experience creating automated data pipelines using modern technology stacks to integrate diverse data sources into data repositories with exception handling and monitoring.Our benefits package includes: (EXCLUDE on perm placements)Comprehensive medical benefitsCompetitive pay, 401(k)Retirement plan…and much more!About INSPYR Solutions: Technology is our focus and quality is our commitment. As a national expert in delivering flexible technology and talent solutions, we strategically align industry and technical expertise with our clients’ business objectives and cultural needs. Our solutions are tailored to each client and include a wide variety of professional services, project, and talent solutions. By always striving for excellence and focusing on the human aspect of our business, we work seamlessly with our talent and clients to match the right solutions to the right opportunities. Learn more about us at inspyrsolutions.com.INSPYR Solutions provides Equal Employment Opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, or genetics. In addition to federal law requirements, INSPYR Solutions complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities.#LI-NS1#LI-Remote",Mid-Senior level,Contract,Information Technology,Banking and Financial Services,2024-05-12
47,Data Engineer,QuantumBricks,2 weeks ago,Over 200 applicants,"Required Qualifications / Skills4 to 7 years of strong SQL skills; SQL Server and PostgreSQL is preferred. experience in any other RDBMS is plus..Proficiency in the Python programming languageAbility to prepare, analyze, and effectively communicate the findings of data analysis to customers, RTC leadership, and outside stakeholders.Strong written/verbal communication skills.Must be able to obtain and maintain a Secret Clearance Python and spark knowledge is plus. Knowledge about Database engineering and Data warehousing Concepts.Experience with Agile based project methodology. Ability to identify risks/issues for the project and manage them accordingly.ResponsibilitiesWrite secure and high-quality code and maintains algorithms that run synchronously with appropriate systems.Develop Extract, Transform, Load (ETL) pipelines for dataWork directly in support of Army modernization priorities including working directly on and around helicopters, missiles, and sensors.Proactively identify hidden problems and patterns in data and uses these insights to drive improvements to coding hygiene and system architecture.",Entry level,Contract,Information Technology,IT Services and IT Consulting,2024-05-12
48,Data Engineer,Paramount+,1 week ago,Over 200 applicants,"Overview & ResponsibilitiesWe are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to resolve the best approaches around data ingestion, constellation, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while designing and maintaining documentation, and mentoring impacted teams. Early on, collaborate with the team on internal initiatives to build strategies that improve company processes. BASIC QUALIFICATIONS:STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis. Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutionsExperience developing solutions to business requirements via hands-on discovery and data exploration. Robust written and verbal communicative savvy, communicating technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions. ADDITIONAL QUALIFICATIONS:Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow. Experience building and deploying applications on a Google Cloud Platform (GCP). Familiarity with ELT/ETL concepts. Data Modeling perspicacity. Code repository experience in GIT. Statistical analyses using tools such as R, Numpy/SciPy with Python. Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. 40023Join the Paramount Streaming Talent Community! Get the inside scoop on life at Paramount Streaming and about career opportunities.Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.Additional InformationHiring Salary Range: $85,600.00 - 125,000.00.The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.https://www.paramount.com/careers/benefitsParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Entry level,Full-time,Information Technology,Entertainment Providers,2024-05-12
49,Hiring for Data Engineer,Persistent Systems,1 week ago,Over 200 applicants,"About PersistentWe are a trusted Digital Engineering and Enterprise Modernization partner, combining deep technical expertise and industry experience to help our clients anticipate what’s next. Our offerings and proven solutions create a unique competitive advantage for our clients by giving them the power to see beyond and rise above. We work with many industry-leading organizations across the world including 14 of the 30 most innovative US companies, 80% of the largest banks in the US and India, and numerous innovators across the healthcare ecosystem.Our disruptor’s mindset, commitment to client success, and agility to thrive in the dynamic environment have enabled us to sustain our growth momentum by reporting $282.9M revenue in Q1FY24, delivering 17.1% Y-o-Y growth. In addition, our total employee count reached 23,130 people this quarter, located in 21 countries across the globe. We’re also pleased to share that Persistent has been named the fastest-growing Indian IT Services brand by Brand Finance. Acknowledging our vertical industry expertise, we were placed as a Leader in Everest Group’s Payments IT Services PEAK Matrix® Assessment 2023. We were also recognized as a Leader in the ISG Provider Lens™ Digital Engineering Services Quadrants U.S. 2023 and the Salesforce Ecosystem Partners 2023 ISG Provider Lens™ Study. Throughout this market-leading growth, we’ve maintained strong employee satisfaction - over 94% of our employees approve of the CEO, and 89% would recommend working at Persistent to a friend.About Position:Role: Data EngineerLocation: Scottsdale AZExperience: 10+Job Type: FTEWhat You'll Do:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologiesExpertise You'll Bring:You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is criticalHighly analytical and data oriented.Experience in SQL, NoSql DatabaseData masking of on prem PII data.Develop API calls with using secure data transfer.Take standard output data to lower environments for pre prod testing!Enable secured channels for data models and data science activities.Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 minsYou have experience with development tools and agile methodologies.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly promotion cycles and company-sponsored higher education and certifications.Opportunity to work with cutting-edge technologies.Employee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsOur company fosters a values-driven and people-centric work environment that enables our employees to:· Accelerate growth, both professionally and personally· Impact the world in powerful, positive ways, using the latest technologies· Enjoy collaborative innovation, with diversity and work-life wellbeing at the core· Unlock global opportunities to work and learn with the industry’s bestLet’s unleash your full potential at Persistent - persistent.com/careers",Mid-Senior level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
50,"Data Engineer 1, 2 or 3",MidAmerican Energy Company,2 weeks ago,,"Job DescriptionThis is a multi-level posting. Candidates may be considered for any of the posted levels, depending on their level of experience and depth of expertise.﻿The data engineer is responsible for the design, implementation and maintenance of the database structures. Conducts analysis, creates system specifications, develops, tests and implements engineering, scientific and business applications, operating systems, and file/database servers. Utilizes existing or new technology in the automation of processes. Evaluates software packages and provides recommendations to management.",Mid-Senior level,Full-time,Information Technology,Utilities,2024-05-12
51,Data Engineer - NBC Sports Next,NBC Sports Next,2 weeks ago,Over 200 applicants,"Company DescriptionWe create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.  At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.  NBC Sports Next is where sports and technology intersect. We’re fueled by our mission to innovate, create larger-than-life events and connect with sports fans through technology. We’re a subdivision of NBC Sports and home to leading technology platforms and digital applications for Youth & Recreational Sports; Golf; and Emerging Media.At NBC Sports Next, we equip more than 30MM players, coaches, athletes, sports administrators and fans in 40 countries with more than 25 sports solution products, including SportsEngine, the largest youth sports club, league and team management platform; SportsEngine Play, the first ever streaming service for youth and amateur sports, GolfNow, the leading online tee time marketplace and provider of golf course operations technology; and GolfPass the ultimate golf membership that connects golfers to exclusive content, tee time credits, instructional content and more.Golf fuses the team behind products and services like GolfNow, TeeOff and GolfPass, which better connects golfers and golf facilities around the world through innovative solutions like cloud-based golf course management and SmartPlay contactless technology and services that create optimum golfing experiences.Job DescriptionGolfNow has an exciting opportunity for an experienced Data Engineer. Working alongside the Data Engineering Team, you'll manage the full lifecycle of our data warehousing needs. You'll read and write complex queries, demonstrate the ability to create database objects (tables, views, stored procedures, user-defined functions), and create and maintain ELT pipelines. Our data warehouse and data operations are built on top of Microsoft and AWS technologies including Redshift, RDS, MSSQL and Python. To perform this job successfully, an individual would need to be able to understand complex business processes, gather requirements, work efficiently, and verify their results.Responsibilities Include But Are Not Limited ToWork within a small team of passionate data engineers and data scientists.Compile user requirements and specifications for reports.Contribute to the management of the day-to-day operations of running our Data Warehouse. Build, analyze, and manage reports and dashboards for business stakeholders.Respond to users to troubleshoot and/or improve existing reports.Collaborate with internal QA on customer acceptance testing.Develop SQL scripts and objects to support reporting functionality and performance. Build data pipelines and ELTs for loading source system data into the data warehouse for further reporting and analysis.Assist in building scalable data models to support reporting and tracking of key business and product metrics.Help identify better practices, tools, and relevant trends that can positively influence the data operations across the business.Other duties may be assigned as needed by management.Strong ability to actively engage in a remote workspace - including, but not limited to, virtual team meetings, connection via team channels (Teams, Slack and Outlook) and ad hoc meetings as requested.Experience working through complex issues to completionOther duties may be assigned as needed by management.QualificationsAll candidates must meet the qualifications below:A minimum of 2+ years of programming or data engineering experience is requiredBachelor’s Degree in Computer Science or related field/relevant industry experience in data engineeringWorking experience developing and refactoring SQL Stored ProceduresA minimum of 1 years working experience with PythonGood understanding and knowledge of T-SQL and Microsoft SQL Server Database Platforms1+ years experience with AWS cloud environmentExperience with AWS ETL tools such as Glue and LambdaExperience using source control with Github, Bitbucket, TFSExperience with modeling data structures in both transactional and analytical platforms.Experience with one of the following BI Tools. (SSRS, Tableau, Power BI)Desired Qualifications Are As FollowsExperience working in Agile environmentExperience with RedshiftExperience with PowerShell scripting is a plusExperience with SSIS is a plusExperience with Apache AirflowExperience managing SDLC process with Atlassian tools. (Jira, Confluence)Able and eager to learn new technologies.Able to easily transition between high-level strategy and day-to-day implementation.Excellent teamwork and collaboration skills.Results-oriented and self-motivated.Fully Remote: This position has been designated as fully remote, meaning that the position is expected to contribute from a non-NBCUniversal worksite, most commonly an employee’s residence.Additional InformationNBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law. NBCUniversal will consider for employment qualified applicants with criminal histories in a manner consistent with relevant legal requirements, including the City of Los Angeles Fair Chance Initiative For Hiring Ordinance, where applicable.If you are a qualified individual with a disability or a disabled veteran, you have the right to request a reasonable accommodation if you are unable or limited in your ability to use or access nbcunicareers.com as a result of your disability. You can request reasonable accommodations by emailing AccessibilitySupport@nbcuni.com.",Associate,Full-time,Other,"Broadcast Media Production and Distribution, Entertainment Providers, and Media Production",2024-05-12
52,Data Engineer,TickPick,5 days ago,Over 200 applicants,"Who We Are:TickPick is a fast growing technology company that is reshaping the secondary ticket marketplace. Through a combination of software development, product innovation and best in class customer experience, we have saved our customers over $60 million in service fees.Since our launch in 2011 we have sold over $1 billion in tickets, and for the last five years, TickPick has been named a Deloitte Technology Fast 500 award winner and has landed on lists of Inc. 5000's and Crain's New York Business' Fast 50.If you are passionate about solving complex problems, and want to see your skills and experience have a direct impact on a fast growing company, TickPick is the place for you. We are building a diverse team, committed to providing the most innovative, transparent, and cost-effective ticket marketplace in the industry.Who You Are:You are a data engineer with strong desire and ability to implement high-impact data movement and management within a growing, technology-first team. In this core role, you will be responsible for building and maintaining data pipelines touching a wide array of tools from the modern data stack, including but not limited to Snowflake, Dagster, dbt, Spark, and Azure Cloud offerings. In addition to working closely with other Analytics-focussed team members you’ll also lead the junior Data Engineer on the team. If you value continual learning and are looking to join a high-visibility and high-impact team at a growing company that’s making data a priority, then this role is for you.Core Responsibilities:Discover opportunities for data acquisition and implementation solutionsDevelop production processes and solutions to model, mine and surface dataImprove and ensure data reliability, quality and efficiencyLead and mentor the junior Data Engineer by providing technical guidance and giving actionable feedbackRequirements:BS or above in Computer Science or a related field, or equivalent personal or professional experienceExperience in leading technical direction and oversightCommunication ability is paramount: you understand the value of open communication and can interact effectively with stakeholders and team membersExperience and competency with at least one cloud services provider (Azure preferred; AWS or GCP also worthwhile)Strong Python and SQL skills, as well as general competency with web languages (HTML/Javascript)Python data competency – knowledge of and experience with, eg, Pandas or other Dataframe libraries. Polars, PySpark, and DuckDB are a plusExperience and competency with at least one general data orchestration tool, eg Airflow, Dagster, or PrefectExperience and competency with web scraping tools, eg Apify (Crawlee), BeautifulSoup, requests, and Scrapydbt or other data modeling experience is a plus Kafka experience is a plus Experience with a dashboarding tool is a plus, eg Looker, Tableau, Superset, Metabase, or StreamlitExperience with managed ETL tools (Fivetran, Hightouch) is worth mentioning if you have it Benefits:A hybrid in-office approach, enabling remote work a portion of each weekHealth Care Plan (Medical, Dental & Vision)Retirement Plan Contribution (401k, IRA)Life Insurance (Basic, Voluntary & AD&D)Paid Time Off (Vacation, Sick & Holidays)Family Leave (Maternity, Paternity)Training & Development$100 Monthly Stipend to Attend Live EventsEmployee OutingsFree Lunch & SnacksThe estimated pay range for this role, based in New York City, is $150,000 - $175,000. This role will be eligible to participate in our company's equity program. Our salary ranges are based on paying competitively for our size and industry, and are one part of many compensation, benefits and other reward opportunities we provide.Individual pay rate decisions are based on a number of factors, including qualifications for the role, experience level, skill set, and balancing internal equity relative to peers at the company.Diversity at TickPick:At TickPick, we know that diversity of all types, in an environment that pursues equity and inclusion, strengthens our organization's culture. When our employees are representative of the communities we serve, with diversity in demographics and a broad set of backgrounds, we provide a superior experience for both our customers and our employees. Fostering an open and supportive environment where our employees are empowered and encouraged to bring their whole selves to the table enables TickPick to thrive. The diverse approaches and collaborative problem solving that result enable us to provide an innovative, nimble, and creative marketplace for our customers and sellers. This belief is central to who we are and what we do, and we are proud of it.TickPick, LLC is proud to be an equal opportunity employer open to all qualified candidates regardless of race, color, religion, national origin, gender, sexual orientation, gender identity or expression, age, mental or physical disability, marital status, citizenship status, military status, protected veteran status or any other category protected by law.",Mid-Senior level,Full-time,"Analyst, Engineering, and Other","Technology, Information and Media, Software Development, and Entertainment Providers",2024-05-12
53,Data Engineer,CAI,3 weeks ago,Over 200 applicants,"CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team, you will construct and maintain the backbone of our data platform, creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs, ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct, manage, and optimize data pipelines for data ingestion, storage, and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage, processing tools, and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance, identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science, Engineering, or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL, Python, and other relevant data manipulation languages.Experience with data modeling, ETL development, and data warehousing solutions, especially with platforms like Snowflake.Demonstrated ability to work with large, complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning, qualification, validation, start-up, project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first, we do not stop until it is right, and we will do whatever it takes to get there.As owners of CAI, we are committed to living our Foundational Principles, both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership, one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self, demonstrate Respect for Others, and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution, 24 days PTO and 5 sick days per year, health insurance at extremely low cost to employee, financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122,000 - $155,000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees, our customers, and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).",Entry level,Full-time,Information Technology,Pharmaceutical Manufacturing,2024-05-12
54,Data Engineer,IntePros,2 weeks ago,Over 200 applicants,"Compensation Range:70-80/hrWelcome to IntePros, a certified woman-owned company specializing in innovative and results-oriented recruiting and staffing solutions. We take immense pride in genuinely understanding what drives and inspires exceptional individuals like you. Your success is our priority, and we are dedicated to actively shaping your long-term career journey. At IntePros, we believe in comprehensive well-being. You have access to our medical, dental, vision, and mental health programs, ensuring your health and wellness are taken care of. To support your continuous growth, we also provide a $1,500 per year education and professional certification fund. Diversity and inclusion are cornerstones of our company ethos. IntePros is proud to be an equal opportunity employer. We do not discriminate in employment on the basis of race, color, religion, sex, pregnancy, gender identity, national origin, sexual orientation, disability, age, veteran or military status, retaliation, or any other characteristic protected by law. We celebrate the rich tapestry of backgrounds and perspectives that make us stronger as a team. Please note that only qualified individuals being considered will be contacted. We appreciate your interest and look forward to potentially embarking on a transformative journey together.Data EngineerIntePros is looking for a highly skilled Data Engineer proficient in Oracle Autonomous Data Warehouse (ADW), AWS cloud services, and SQL/database technologies to spearhead the development and maintenance of robust data architecture, ensuring optimal performance and reliability of data solutions, and supporting our oil and gas client's data needs.Responsibilities: Design, build, and maintain efficient data pipelines and ETL processes using Oracle ADW and AWS technologies. Implement data models and database designs to support business requirements and ensure scalability and performance. Develop and optimize SQL queries for complex data retrieval and analysis tasks. Collaborate with cross-functional teams (such as subject matter experts, analysts, and software engineers) to understand data needs and deliver solutions. Monitor and troubleshoot database performance issues, ensuring high levels of data quality and availability. Implement best practices in data governance and security within Oracle ADW and AWS environments. Evaluate and recommend new tools and technologies to enhance data processing and storage capabilities. Document technical specifications, data lineage, and processes for future reference and maintenance.What are the top MUST HAVE skill sets (technical) that are required?Expertise in Oracle Autonomous Data Warehouse (ADW) and AWS cloud services, with hands-on experience in designing, building, and maintaining data solutions.Strong proficiency in SQL and database technologies (e.g., Oracle, PostgreSQL, Snowflake), with the ability to develop and optimize complex queries for data retrieval and analysis tasks.Experience in data modeling, schema design, and performance tuning, ensuring scalability, efficiency, and reliability of data architectures.What are top three PREFERRED skill sets (technical)?AWS certifications (e.g., AWS Certified Solutions Architect, AWS Certified Data Analytics – Specialty), demonstrating a deep understanding of AWS cloud services and best practices.Familiarity with other cloud platforms and technologies beyond AWS, such as Google Cloud Platform (GCP) or Microsoft Azure, broadening the scope of expertise in cloud-based data solutions.Experience with big data technologies and frameworks, such as Apache Spark or Hadoop, enriching the skill set for handling large-scale data processing and analytics tasks.Soft Skill requirements (team fit/personality requirements)Effective communicationOrganization skillsCompensation: 70-80 per hourBenefits: Healthcare Eligible, Dental Eligible, 401k Eligible, Tuition Reimbursement Eligible",Entry level,Full-time,Information Technology,IT Services and IT Consulting,2024-05-12
55,Software Engineer (Front-End / Map),Paces,5 days ago,Over 200 applicants,"In the next 30 years, the world will transform every part of the built environment to be climate positive green infrastructure. Knowing what, where, and how to build infrastructure like solar farms is one of the great opportunities of our time.\ \ Paces is software for green infrastructure developers to identify the best places to build and manage their projects. Our software supports renewable energy, EV charging, carbon sequestration and data center customers with interconnection, permitting and siting of their projects. We are venture backed from Resolute Ventures & Y Combinator.🌳 TL;DRWe are looking for a front-end expert to shape user experiences to join us as we scale up. You will have the chance to build things from ground up and own a large portion of the tech stack.🏆 What You’ll AchieveLead front-end development, collaborate very closely with other engineers on a variety of projectsCollaborate and iterate with designers to translate designs into codeOptimize speed and scalability of our data heavy platformConduct user researches, improve user experience and identify new opportunitiesCollaborate closely with our CTO and team to directly impact product roadmap📈 RequirementsProficient with React, JavaScript / TypesScriptExperience working with map frameworks, such as Leaflet.js, Mapbox, and Google MapsYou are a proactive and fast learner and able to pick up new things quicklyYou genuinely want to build something people want, enjoy talking to users and learning their needs✨ About YouYou will thrive in our culture if you:Have a strong bias towards action and prioritize executionShare our passion to build something that fights climate changeEasily handle the unstructured environment of fast moving startupsHave the hunger to grow together with Paces as we scale up🚀 Bonus PointsPrevious experience at a high-growth, fast-paced startupPrevious experience scaling up data intensive, AI and analytics heavy solutionsPrevious experience building and deploying on AWSFamiliar with Python💰 Compensation And Benefits130K - 200K annual compensationCompetitive equity compensation401(k) matchingHealth, Dental and Vision insuranceHybrid working in the office 2-4 times per week",Entry level,Full-time,Engineering and Information Technology,Software Development,2024-05-12
56,Data Engineer II,Stride Funding,2 weeks ago,,"Unfortunately we do not offer visa sponsorship for this position. Only candidates authorized to work in the United States will be considered.About UsStride Funding is a venture-backed, mission-driven startup transforming access to education and career pathways. We are revolutionizing the way employers attract and retain critical talent, while simultaneously tackling the student debt crisis. (Yep, we think BIG.) Our innovative platform meaningfully connects employers, educational institutions, and diverse talent to drive mutual benefit—using accessible education financing as the thread. We like to think of ourselves as more than a fintech; we’re a catalyst for economic mobility.A Forbes Fintech 50 company, portfolio company of SHRM (Society of Human Resource Management — the largest HR organization out there!) and recipient of “Startup of the Year” by StartUp Boston, Stride is driven by our commitment to social impact and innovation. We are reshaping the future of the workforce one opportunity at a time. Join us on our journey to give power to learners and unlock fulfilling careers that drive positive change in their communities and beyond.What We NeedWe are seeking a Data Engineer to build & operate reliable data pipelines that ingest and make accessible to our team and partners the data on hundreds of millions of dollars worth of student loans, educational enrollment statuses and employment data.The ideal candidate has both analytics and programming experience (SQL and Python) and is passionate about both high performance data pipelines as well as the business side of fintech.At Stride we run a DevOps culture where the engineers have full ownership of the code they write & the infrastructure on which it runs. Candidates should be enthused about making substantial contributions to the architecture driving the product roadmap and the Stride business, and achieving tremendous personal growth with us along the way!Our modern Data Technology Stack consists primarily of Airflow, dbt, Postgresql, Superset, BigQuery, Python and SQL.What you will do:Build reliable data integration pipelines & interfaces to ensure that engagement data and financial operating data is regularly synced into our data lake and accessible to our business users and partnersPartner with stakeholders in finance, operations and business development departments to ensure that their data sets are reliably ingested into our data warehouse and their questions or reports can be answered programmaticallyEnsure via automated testing and edge case handling that we can detect any errors with upstream data or data processing and that all reports contain the data as expected Support Stride’s engineering & product teams by anonymizing upstream data sets to ensure that our development & staging environments protect consumer privacy but also enable rapid iterations on our productParticipate in on-call rotations and ensure by building self-healing and resilient systems and leveraging infrastructure as code and monitoring tools that our systems are highly availableWhat you will need:3+ years of experience as a data engineer, or equivalent experience building data pipelines3+ years of experience with elements of the following technologies: Data Analytics: Airflow, DBT Business Intelligence Systems: Tableau, Looker, Sisense, Apache SupersetLanguages: Python, SQL---- Databases: SQL; NoSQL a bonus----  Bonus – Data Warehousing: Snowflake, BigQuery Bonus -- Cloud Infrastructure: AWS or Google Cloud Experience Bonus -- DevOps: Experience with modern cloud and container tooling such as Docker, Kubernetes, Terraform, etc. Strong communication and collaboration skills, with the ability to effectively communicate the complexities of technical programs to both technical and nontechnical stakeholdersDesire to mentor and collaborate with other members of the teamWillingness to roll your sleeves up to rapidly acquire competencies in a wide range of technical disciplinesBachelor’s degree in Computer Science, Software Engineering, Information Systems, or equivalent experienceWhat we give in return:Competitive cash and equity compensation Health benefits (health & dental)401kCommuter benefitsFlexible PTO policyOpportunities to grow and perform in a fast-paced environment alongside a stellar teamIf you are a highly driven individual with a passion for technology, and you thrive in a dynamic and fast-paced environment, we want to hear from you! Join us in revolutionizing the workforce solution industry and making a meaningful impact on businesses worldwide. Apply now to be a part of our growing team!We are committed to creating a diverse and inclusive workplace where all employees feel valued, respected, and empowered to contribute their unique perspectives and talents. Stride is an equal opportunity employer and prohibits discrimination and harassment of any kind. We embrace diversity and are dedicated to providing equal employment opportunities to all individuals regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other characteristic protected by law.The salary range for this position is competitive and will be commensurate with the candidate's experience, qualifications, and industry knowledge, ranging between $100,000 to $130,000 annually. In addition to the base salary, we offer an attractive equity component as part of our compensation package, providing an opportunity for eligible employees to share in the success and growth of our company. We are committed to offering competitive compensation and benefits packages to attract and retain top talent.",Not Applicable,Full-time,Information Technology,Financial Services,2024-05-12
